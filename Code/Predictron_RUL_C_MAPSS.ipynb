{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lk196J1yW_7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8Da2Q6OyhVl"
   },
   "outputs": [],
   "source": [
    "col_names = ['unit', 'cycle', 'op_set_1', 'op_set_2', 'op_set_3',\n",
    "             'sensor1', 'sensor2', 'sensor3', 'sensor4', 'sensor5', 'sensor6',\n",
    "             'sensor7', 'sensor8', 'sensor9', 'sensor10', 'sensor11', 'sensor12', \n",
    "             'sensor13', 'sensor14', 'sensor15', 'sensor16', 'sensor17',\n",
    "             'sensor18', 'sensor19', 'sensor20', 'sensor21']\n",
    "\n",
    "\n",
    "data = pd.read_csv('train_FD001.txt',\n",
    "                   delimiter=' ',\n",
    "                   names=col_names,\n",
    "                   index_col=False,\n",
    "                   skipinitialspace=True\n",
    "                   )\n",
    "\n",
    "data.set_index(['unit', 'cycle'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "2XywvDOY__Dv",
    "outputId": "407c13c2-601b-49e5-b055-e1e565d8645c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>op_set_1</th>\n",
       "      <th>op_set_2</th>\n",
       "      <th>op_set_3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">100</th>\n",
       "      <th>196</th>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.49</td>\n",
       "      <td>1597.98</td>\n",
       "      <td>1428.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>551.43</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>9065.52</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.07</td>\n",
       "      <td>519.49</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.60</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>22.9735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.0016</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1604.50</td>\n",
       "      <td>1433.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.86</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>9065.11</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.04</td>\n",
       "      <td>519.68</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8136.50</td>\n",
       "      <td>8.5139</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.1594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1602.46</td>\n",
       "      <td>1428.18</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.94</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>9065.90</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.09</td>\n",
       "      <td>520.01</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>8141.05</td>\n",
       "      <td>8.5646</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.44</td>\n",
       "      <td>22.9333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.23</td>\n",
       "      <td>1605.26</td>\n",
       "      <td>1426.53</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.68</td>\n",
       "      <td>2388.25</td>\n",
       "      <td>9073.72</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.39</td>\n",
       "      <td>519.67</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8139.29</td>\n",
       "      <td>8.5389</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.29</td>\n",
       "      <td>23.0640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.85</td>\n",
       "      <td>1600.38</td>\n",
       "      <td>1432.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.79</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>9061.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.20</td>\n",
       "      <td>519.30</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.33</td>\n",
       "      <td>8.5036</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20631 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            op_set_1  op_set_2  op_set_3  ...  sensor19  sensor20  sensor21\n",
       "unit cycle                                ...                              \n",
       "1    1       -0.0007   -0.0004     100.0  ...     100.0     39.06   23.4190\n",
       "     2        0.0019   -0.0003     100.0  ...     100.0     39.00   23.4236\n",
       "     3       -0.0043    0.0003     100.0  ...     100.0     38.95   23.3442\n",
       "     4        0.0007    0.0000     100.0  ...     100.0     38.88   23.3739\n",
       "     5       -0.0019   -0.0002     100.0  ...     100.0     38.90   23.4044\n",
       "...              ...       ...       ...  ...       ...       ...       ...\n",
       "100  196     -0.0004   -0.0003     100.0  ...     100.0     38.49   22.9735\n",
       "     197     -0.0016   -0.0005     100.0  ...     100.0     38.30   23.1594\n",
       "     198      0.0004    0.0000     100.0  ...     100.0     38.44   22.9333\n",
       "     199     -0.0011    0.0003     100.0  ...     100.0     38.29   23.0640\n",
       "     200     -0.0032   -0.0005     100.0  ...     100.0     38.37   23.0522\n",
       "\n",
       "[20631 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "aPKIQ9ta92z-",
    "outputId": "43c2fdcf-cef4-4a6f-f788-011b021afb45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_set_1</th>\n",
       "      <th>op_set_2</th>\n",
       "      <th>op_set_3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cycle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.9983</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.32</td>\n",
       "      <td>1358.61</td>\n",
       "      <td>1137.23</td>\n",
       "      <td>5.48</td>\n",
       "      <td>8.00</td>\n",
       "      <td>194.64</td>\n",
       "      <td>2222.65</td>\n",
       "      <td>8341.91</td>\n",
       "      <td>1.02</td>\n",
       "      <td>42.02</td>\n",
       "      <td>183.06</td>\n",
       "      <td>2387.72</td>\n",
       "      <td>8048.56</td>\n",
       "      <td>9.3461</td>\n",
       "      <td>0.02</td>\n",
       "      <td>334</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14.73</td>\n",
       "      <td>8.8071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.9982</td>\n",
       "      <td>0.8408</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.90</td>\n",
       "      <td>1353.22</td>\n",
       "      <td>1125.78</td>\n",
       "      <td>3.91</td>\n",
       "      <td>5.71</td>\n",
       "      <td>138.51</td>\n",
       "      <td>2211.57</td>\n",
       "      <td>8303.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>42.20</td>\n",
       "      <td>130.42</td>\n",
       "      <td>2387.66</td>\n",
       "      <td>8072.30</td>\n",
       "      <td>9.3774</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.41</td>\n",
       "      <td>6.2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.9988</td>\n",
       "      <td>0.6218</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>537.31</td>\n",
       "      <td>1256.76</td>\n",
       "      <td>1047.45</td>\n",
       "      <td>7.05</td>\n",
       "      <td>9.02</td>\n",
       "      <td>175.71</td>\n",
       "      <td>1915.11</td>\n",
       "      <td>8001.42</td>\n",
       "      <td>0.94</td>\n",
       "      <td>36.69</td>\n",
       "      <td>164.22</td>\n",
       "      <td>2028.03</td>\n",
       "      <td>7864.87</td>\n",
       "      <td>10.8941</td>\n",
       "      <td>0.02</td>\n",
       "      <td>309</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.08</td>\n",
       "      <td>8.6723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.0077</td>\n",
       "      <td>0.8416</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.51</td>\n",
       "      <td>1354.03</td>\n",
       "      <td>1126.38</td>\n",
       "      <td>3.91</td>\n",
       "      <td>5.71</td>\n",
       "      <td>138.46</td>\n",
       "      <td>2211.58</td>\n",
       "      <td>8303.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>41.96</td>\n",
       "      <td>130.72</td>\n",
       "      <td>2387.61</td>\n",
       "      <td>8068.66</td>\n",
       "      <td>9.3528</td>\n",
       "      <td>0.02</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.59</td>\n",
       "      <td>6.4701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0005</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>537.07</td>\n",
       "      <td>1257.71</td>\n",
       "      <td>1047.93</td>\n",
       "      <td>7.05</td>\n",
       "      <td>9.03</td>\n",
       "      <td>175.05</td>\n",
       "      <td>1915.10</td>\n",
       "      <td>7993.23</td>\n",
       "      <td>0.94</td>\n",
       "      <td>36.89</td>\n",
       "      <td>164.31</td>\n",
       "      <td>2028.00</td>\n",
       "      <td>7861.23</td>\n",
       "      <td>10.8963</td>\n",
       "      <td>0.02</td>\n",
       "      <td>309</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.13</td>\n",
       "      <td>8.5286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       op_set_1  op_set_2  op_set_3  ...  sensor19  sensor20  sensor21\n",
       "cycle                                ...                              \n",
       "1       34.9983    0.8400     100.0  ...    100.00     14.73    8.8071\n",
       "2       41.9982    0.8408     100.0  ...    100.00     10.41    6.2665\n",
       "3       24.9988    0.6218      60.0  ...     84.93     14.08    8.6723\n",
       "4       42.0077    0.8416     100.0  ...    100.00     10.59    6.4701\n",
       "5       25.0005    0.6203      60.0  ...     84.93     14.13    8.5286\n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single = data.loc[1]\n",
    "single.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7OVKCip05Ik"
   },
   "outputs": [],
   "source": [
    "# To-Do - Build a time series window class that can produce a variable length \n",
    "# window with the same number of steps as there are number of run cycles.\n",
    "\n",
    "# Reference link on tensorflow website here:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "# NOTES: The problem inherently with the data set provided for the Predictron\n",
    "# architecture as it, is that it was designed to cycle through 2D representations \n",
    "# of mazes to find a singular known target. For the CMAPSS data where trying to\n",
    "# cycle through a series of states until we arrive a single state that represents \n",
    "# the entire system. \n",
    "\n",
    "# When using time series windows like from the example above, it's built with the \n",
    "# idea that we'll be looking into the future N number of times, whereas with the \n",
    "# Predictron as applied to CMAPSS we're trying to determine how many remaining\n",
    "# states are left. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqhKjJYcNzQ-"
   },
   "source": [
    "## The Predictron Model Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "TQKSGkONfKBG",
    "outputId": "aac0e8a4-cd63-4491-daee-c9d02fc39379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.3.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.6/dist-packages\n",
      "Requires: absl-py, grpcio, tensorflow-estimator, tensorboard, wrapt, protobuf, wheel, numpy, gast, h5py, opt-einsum, keras-preprocessing, scipy, six, astunparse, termcolor, google-pasta\n",
      "Required-by: fancyimpute\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FhCVo6d4xrQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Conv1D, Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MSE\n",
    "import tensorflow.keras\n",
    "\n",
    "class Predictron(tf.keras.Model):\n",
    "  def __init__(self, dataset, RUL, max_depth):\n",
    "    print(dataset)\n",
    "    self.inputs = dataset\n",
    "    self.targets = RUL\n",
    "    self.learning_rate = 0.001\n",
    "    self.size = 1 # dataset.shape[0] -- This was originally maze_size, which was originally 20\n",
    "                  # this either needs to be 1 or the 24\n",
    "    self.max_depth = max_depth\n",
    "    self.batch_size = 5\n",
    "    # self.run_shape = (self.batch_size, self.size, 24)\n",
    "\n",
    "    self.rewards = None\n",
    "    self.gammas = None\n",
    "    self.lambdas = None\n",
    "    self.values = None\n",
    "    self.preturns = None\n",
    "    self.lambda_preturns = None\n",
    "\n",
    "  def build(self):\n",
    "    self.build_model()\n",
    "    self.build_loss()\n",
    "\n",
    "  def iter_func(self, state):\n",
    "    value_net = Flatten()(state)\n",
    "    value_net = BatchNormalization()(value_net)\n",
    "    value_net = Dense(1)(value_net)\n",
    "\n",
    "    net = Conv1D(24, 3, input_shape=state.shape)(state)\n",
    "    net = BatchNormalization()(net)\n",
    "    flat_net = Flatten()(net)\n",
    "\n",
    "    reward = Dense(24)(flat_net)\n",
    "    reward = BatchNormalization()(reward)\n",
    "    reward = Dense(1)(reward)\n",
    "\n",
    "    gamma = Dense(24)(flat_net)\n",
    "    gamma = BatchNormalization()(gamma)\n",
    "    gamma = Dense(1)(gamma)\n",
    "\n",
    "    lambda_net = Dense(24)(flat_net)\n",
    "    lambda_net = BatchNormalization()(lambda_net)\n",
    "    lambda_net = Dense(1)(lambda_net)\n",
    "\n",
    "    net = Conv1D(24, 3, input_shape=state.shape)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    net = Conv1D(24, 3, input_shape=state.shape)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "\n",
    "    return net, reward, gamma, lambda_net, value_net\n",
    "  \n",
    "  def build_model(self):\n",
    "    # print(self.run_shape)\n",
    "    state = Conv1D(24, 3, batch_size=batch_size)(self.inputs) # removed input_shape = self.run_shape\n",
    "    state = BatchNormalization()(state)\n",
    "    state = Conv1D(24, 3, batch_size=batch_size)(state) # removed input_shape = self.run_shape\n",
    "    state = BatchNormalization()(state)\n",
    "    print(state.shape)\n",
    "    \n",
    "    iter_template = tf.compat.v1.make_template('iterator', self.iter_func)\n",
    "\n",
    "    rewards_arr = []\n",
    "    gammas_arr = []\n",
    "    lambdas_arr = []\n",
    "    values_arr = []\n",
    "\n",
    "    for k in range(self.max_depth):\n",
    "      print(f'iteration: {k}')\n",
    "      print(state)\n",
    "      state, reward, gamma, lambda_, value = self.iter_func(state)\n",
    "      rewards_arr.append(reward)\n",
    "      gammas_arr.append(gamma)\n",
    "      lambdas_arr.append(lambda_)\n",
    "      values_arr.append(value)\n",
    "      print(lambdas_arr)\n",
    "\n",
    "    _, _, _, _, value = self.iter_func(state)\n",
    "    values_arr.append(value)\n",
    "\n",
    "    bs = tf.shape(self.inputs)[0]\n",
    "    print(f'BS: {bs}')\n",
    "\n",
    "    # I think the negative output size is happening here because we're still defining\n",
    "    # self.size, which I don't think is userful for the C-MAPSS dataset since it's\n",
    "    # on dimensional. So far options for self.size are:\n",
    "    # 1. remove it\n",
    "    # 2. set it to the feature size of the dataset (I think we've done that already)\n",
    "    # 3. set it dynamically to the current state shape?\n",
    "    #\n",
    "    # Update - The negative output size isn't happening here, but it might need to be\n",
    "    # rewritten to accomodate 1D data\n",
    "    self.rewards = tf.stack(rewards_arr, axis=1)\n",
    "    self.rewards = tf.reshape(self.rewards, [bs, self.max_depth, self.size]) \n",
    "    self.rewards = tf.concat(values=[tf.zeros(shape=[bs, 1, self.size], dtype=tf.float32),\n",
    "                                      self.rewards], axis=1, name='rewards')\n",
    "    self.gammas = tf.stack(gammas_arr, axis=1)\n",
    "    self.gammas = tf.reshape(self.gammas, [bs, self.max_depth, self.size])\n",
    "    self.gammas = tf.concat_v2(values=[tf.ones(shape=[bs, 1, self.size], dtype=tf.float32), self.gammas],\n",
    "                              axis=1, name='gammas')\n",
    "    self.lambdas = tf.stack(lambdas_arr, axis=1)\n",
    "    self.lambdas = tf.reshape(self.lambdas, [-1, self.max_depth, self.size])\n",
    "    self.values = tf.stack(values_arr, axis=1)\n",
    "    self.values = tf.reshape(self.values, [-1, (self.max_depth +1), self.size])\n",
    "\n",
    "    self.build_preturns()\n",
    "    self.build_lambda_preturns()\n",
    "\n",
    "  def build_preturns(self):\n",
    "    g_preturns = []\n",
    "    for k in range(self.max_depth, -1, -1):\n",
    "      g_k = self.values[:, k, :]\n",
    "      for kk in range(k, 0, -1):\n",
    "        g_k = self.rewards[:, kk, :] + self.gammas[:, kk, :] * g_k\n",
    "      g_preturns.append(g_k)\n",
    "    g_preturns = g_preturns[::-1]\n",
    "    self.preturns = tf.stack(g_preturns, axis=1, name='preturns')\n",
    "    self.g_preturns = tf.reshape(self.g_preturns, [-1, (self.max_depth + 1), self.size])\n",
    "\n",
    "  def build_lambda_preturns(self):\n",
    "    g_k = self.values[:, -1, :]\n",
    "    for k in range(self.max_depth -1, -1, -1):\n",
    "      g_k = (1 - self.lambdas[:, k, :]) * self.values[:, k, :] + self.lambdas[:, k, :] * (self.rewards[:, k + 1, :] + self.gammas[:, k + 1, :] * g_k)\n",
    "    self.g_lambda_preturns = g_k\n",
    "\n",
    "  def build_loss(self):\n",
    "    #need to rebuild this to a loop through each run cycle\n",
    "\n",
    "    self.targets_expanded = tf.expand_dims(self.target, 1) # \n",
    "    self.targets_tiled = tf.tile(self.targets_expanded, [1, self.max_depth +1, 1])\n",
    "    self.loss_preturns = MSE(self.g_preturns, self.targets_tiled)\n",
    "    tf.compat.v1.losses.add_loss(self.loss_preturns)\n",
    "    tf.summary.scalar('Loss Preturns', self.loss_preturns)\n",
    "    self.loss_lambda_preturns - MSE(self.g_lambda_preturns, self.targets)\n",
    "    tf.compat.v1.losses.add_loss('Loss Lambda Preturns', self.loss_lambda_preturns)\n",
    "    self.total_loss = losses.get_total_loss(name='Total Loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1mAksv0Nuq_"
   },
   "source": [
    "## The Training Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpvYgaJBhIdO"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import six.moves.queue as queue\n",
    "from six.moves import range\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# tf.flags.DEFINE_string('train_dir', './ckpts/predictron_train',\n",
    "#                        'dir to save checkpoints and TB logs')\n",
    "# tf.flags.DEFINE_integer('max_steps', 10000000, 'num of batches')\n",
    "# tf.flags.DEFINE_float('learning_rate', 1e-3, 'learning rate')\n",
    "\n",
    "# tf.flags.DEFINE_integer('batch_size', 128, 'batch size')\n",
    "# tf.flags.DEFINE_integer('maze_size', 20, 'size of maze (square)')\n",
    "# tf.flags.DEFINE_float('maze_density', 0.3, 'Maze density')\n",
    "# tf.flags.DEFINE_integer('max_depth', 16, 'maximum model depth')\n",
    "# tf.flags.DEFINE_float('max_grad_norm', 10., 'clip grad norm into this value')\n",
    "# tf.flags.DEFINE_boolean('log_device_placement', False,\n",
    "#                         \"\"\"Whether to log device placement.\"\"\")\n",
    "# tf.flags.DEFINE_integer('num_threads', 10, 'num of threads used to generate mazes.')\n",
    "\n",
    "train_dir = '/'\n",
    "max_steps = 10000\n",
    "learning_rate = 0.0001\n",
    "batch_size = 32\n",
    "# define 'size' after dataframe import\n",
    "max_depth = 10\n",
    "max_grad_norm = 10.\n",
    "log_device_placement = False\n",
    "num_threads = 10\n",
    "\n",
    "\n",
    "# logging.basicConfig()\n",
    "# logger = logging.getLogger('training')\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def train():\n",
    "  # config = FLAGS\n",
    "\n",
    "  # global_step = tf.get_variable(\n",
    "  #   'global_step', [],\n",
    "  #   initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "  sensor_data_ph = tf.Variable(tf.ones((1, 100, 24, 1), tf.float32))\n",
    "  labels_ph = tf.Variable(tf.zeros((24), tf.float32))\n",
    "\n",
    "  model = Predictron(sensor_data_ph, labels_ph, max_depth)\n",
    "  model.build()\n",
    "\n",
    "  loss = model.total_loss\n",
    "  loss_preturns = model.loss_preturns\n",
    "  loss_lambda_preturns = model.loss_lambda_preturns\n",
    "\n",
    "  opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "  grad_vars = opt.get_gradients(loss, tf.trainable_variables())\n",
    "  grads, vars = zip(*grad_vars)\n",
    "  grads_clipped, _ = tf.clip_by_global_norm(grads, FLAGS.max_grad_norm)\n",
    "  grad_vars = zip(grads_clipped, vars)\n",
    "  apply_gradient_op = opt.apply_gradients(grad_vars, global_step=global_step)\n",
    "\n",
    "  # update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "  # update_op = tf.group(*update_ops)\n",
    "  # # Group all updates to into a single train op.\n",
    "  # train_op = tf.group(apply_gradient_op, update_op)\n",
    "\n",
    "  # init = tf.global_variables_initializer()\n",
    "  # sess = tf.Session()\n",
    "  # sess.run(init)\n",
    "\n",
    "  # saver = tf.train.Saver(tf.global_variables())\n",
    "  # tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "  train_dir = os.path.join(FLAGS.train_dir, 'max_steps_{}'.format(FLAGS.max_depth))\n",
    "  # summary_merged = tf.summary.merge_all()\n",
    "  # summary_writer = tf.summary.FileWriter(train_dir, sess.graph)\n",
    "\n",
    "  col_names = ['unit', 'cycle', 'op_set_1', 'op_set_2', 'op_set_3',\n",
    "              'sensor1', 'sensor2', 'sensor3', 'sensor4', 'sensor5', 'sensor6',\n",
    "              'sensor7', 'sensor8', 'sensor9', 'sensor10', 'sensor11', 'sensor12', \n",
    "              'sensor13', 'sensor14', 'sensor15', 'sensor16', 'sensor17',\n",
    "              'sensor18', 'sensor19', 'sensor20', 'sensor21']\n",
    "  \n",
    "  data_master = pd.DataFrame(columns=col_names)\n",
    "\n",
    "  data_master.set_index(['unit', 'cycle'], inplace=True)\n",
    "  \n",
    "  def read_cmapss(file):\n",
    "    df = pd.read_csv(file,\n",
    "                      delimiter=' ',\n",
    "                      names=col_names,\n",
    "                      index_col=False,\n",
    "                      skipinitialspace=True\n",
    "                      )\n",
    "    df.set_index(['unit', 'cycle'], inplace=True)\n",
    "    # for unit in df:\n",
    "    #   sensor_data = unit.to_numpy\n",
    "    #   labels = sensor_data.shape[1]\n",
    "    #   frame_queue.put((sensor_data, labels))\n",
    "    data_master.append(df)\n",
    "\n",
    "  def cmapss_queue():\n",
    "    dat_dir = '/'\n",
    "    for file in glob.glob(os.path.join(dat_dir, '.txt')):\n",
    "      read_cmapss(file)\n",
    "\n",
    "  # for thread_i in range(num_threads):\n",
    "  #   t = threading.Thread(target=cmapss_queue)\n",
    "  #   t.start()\n",
    "\n",
    "  for step in range(max_steps):\n",
    "    print(\"I am at Max_steps in training\")\n",
    "    start_time = time.time()\n",
    "    sensor_data_np, labels_np = frame_queue.get()\n",
    "\n",
    "    _, loss_value, loss_preturns_val, loss_lambda_preturns_val, summary_str = sess.run(\n",
    "      [train_op, loss, loss_preturns, loss_lambda_preturns, summary_merged],\n",
    "      feed_dict={\n",
    "        sensor_data_ph: sensor_data_np,\n",
    "        labels_ph: labels_np\n",
    "      })\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "    if step % 10 == 0:\n",
    "      num_examples_per_step = batch_size\n",
    "      examples_per_sec = num_examples_per_step / duration\n",
    "      sec_per_batch = duration\n",
    "\n",
    "      format_str = (\n",
    "        '%s: step %d, loss = %.4f, loss_preturns = %.4f, loss_lambda_preturns = %.4f (%.1f examples/sec; %.3f '\n",
    "        'sec/batch)')\n",
    "      logger.info(format_str % (datetime.datetime.now(), step, loss_value, loss_preturns_val, loss_lambda_preturns_val,\n",
    "                                examples_per_sec, sec_per_batch))\n",
    "      print(f\"{datetime.datetime.now()}, step {step}, loss = {loss_value}, loss_preturns = {loss_preturns_val}, loss_lambda_preturns = {loss_lambda_preturns_val}\")\n",
    "\n",
    "    # if step % 100 == 0:\n",
    "    #   summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "    # Save the model checkpoint periodically.\n",
    "    # if step % 1000 == 0 or (step + 1) == max_steps:\n",
    "    #   checkpoint_path = os.path.join(train_dir, 'model.ckpt')\n",
    "    #   saver.save(sess, checkpoint_path, global_step=step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "agDe5MGxEAmz",
    "outputId": "e0b45d82-e612-4f6a-f919-8ba20dff6837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1, 100, 24, 1) dtype=float32, numpy=\n",
      "array([[[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]]], dtype=float32)>\n",
      "(1, 100, 20, 24)\n",
      "iteration: 0\n",
      "tf.Tensor(\n",
      "[[[[-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   ...\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]]\n",
      "\n",
      "  [[-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   ...\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]]\n",
      "\n",
      "  [[-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   ...\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   ...\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]]\n",
      "\n",
      "  [[-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   ...\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]]\n",
      "\n",
      "  [[-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   ...\n",
      "   [-0.30973434  0.4164496   0.02719295 ... -0.12441047 -0.08611278\n",
      "    -0.03347215]\n",
      "   [-0.3097343   0.41644964  0.02719302 ... -0.12441044 -0.08611275\n",
      "    -0.03347213]\n",
      "   [-0.3097343   0.41644964  0.02719302 ... -0.12441044 -0.08611275\n",
      "    -0.03347213]]]], shape=(1, 100, 20, 24), dtype=float32)\n",
      "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.47922373]], dtype=float32)>]\n",
      "iteration: 1\n",
      "tf.Tensor(\n",
      "[[[[ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   ...\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]]\n",
      "\n",
      "  [[ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   ...\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]]\n",
      "\n",
      "  [[ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   ...\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.19773163 -0.29824507  0.37830764 ...  0.23106182 -0.55934733\n",
      "     0.0803538 ]\n",
      "   [ 0.19773163 -0.29824504  0.3783076  ...  0.23106188 -0.5593474\n",
      "     0.08035378]\n",
      "   [ 0.19773161 -0.29824504  0.3783077  ...  0.23106183 -0.5593473\n",
      "     0.0803538 ]\n",
      "   ...\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]]\n",
      "\n",
      "  [[ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   ...\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]]\n",
      "\n",
      "  [[ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   ...\n",
      "   [ 0.19773158 -0.29824507  0.37830764 ...  0.23106183 -0.55934715\n",
      "     0.0803538 ]\n",
      "   [ 0.19773166 -0.298245    0.37830764 ...  0.23106183 -0.55934733\n",
      "     0.08035374]\n",
      "   [ 0.19773161 -0.2982451   0.3783077  ...  0.2310618  -0.55934745\n",
      "     0.08035383]]]], shape=(1, 100, 14, 24), dtype=float32)\n",
      "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.47922373]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.59365267]], dtype=float32)>]\n",
      "iteration: 2\n",
      "tf.Tensor(\n",
      "[[[[-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   ...\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]]\n",
      "\n",
      "  [[-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   ...\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]]\n",
      "\n",
      "  [[-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   ...\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.3895274   0.34433913 -0.7645715  ...  0.0776661   0.18352486\n",
      "    -0.89608234]\n",
      "   [-0.3895275   0.34433904 -0.7645713  ...  0.07766612  0.1835248\n",
      "    -0.89608234]\n",
      "   [-0.38952765  0.34433898 -0.7645713  ...  0.0776661   0.18352479\n",
      "    -0.89608234]\n",
      "   ...\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]]\n",
      "\n",
      "  [[-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   ...\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]]\n",
      "\n",
      "  [[-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   ...\n",
      "   [-0.3895276   0.34433898 -0.7645713  ...  0.07766612  0.18352476\n",
      "    -0.89608234]\n",
      "   [-0.3895274   0.34433892 -0.76457137 ...  0.07766619  0.18352473\n",
      "    -0.89608234]\n",
      "   [-0.38952744  0.344339   -0.7645713  ...  0.07766622  0.18352476\n",
      "    -0.8960823 ]]]], shape=(1, 100, 8, 24), dtype=float32)\n",
      "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.47922373]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.59365267]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.75164497]], dtype=float32)>]\n",
      "iteration: 3\n",
      "tf.Tensor(\n",
      "[[[[-0.02726807 -0.67291933  0.10142369 ...  0.21196483 -0.1456777\n",
      "    -0.11049716]\n",
      "   [-0.02726807 -0.67291933  0.10142369 ...  0.21196483 -0.1456777\n",
      "    -0.11049716]]\n",
      "\n",
      "  [[-0.02726807 -0.67291933  0.10142369 ...  0.21196483 -0.1456777\n",
      "    -0.11049716]\n",
      "   [-0.02726807 -0.67291933  0.10142369 ...  0.21196483 -0.1456777\n",
      "    -0.11049716]]\n",
      "\n",
      "  [[-0.02726807 -0.67291933  0.10142369 ...  0.21196483 -0.1456777\n",
      "    -0.11049716]\n",
      "   [-0.02726807 -0.67291933  0.10142369 ...  0.21196483 -0.1456777\n",
      "    -0.11049716]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.02726823 -0.67291945  0.10142358 ...  0.21196486 -0.14567766\n",
      "    -0.11049719]\n",
      "   [-0.02726811 -0.67291933  0.10142364 ...  0.21196492 -0.1456777\n",
      "    -0.11049713]]\n",
      "\n",
      "  [[-0.02726807 -0.67291933  0.10142369 ...  0.21196483 -0.1456777\n",
      "    -0.11049716]\n",
      "   [-0.02726807 -0.67291933  0.10142369 ...  0.21196483 -0.1456777\n",
      "    -0.11049716]]\n",
      "\n",
      "  [[-0.02726801 -0.67291933  0.10142366 ...  0.2119648  -0.14567767\n",
      "    -0.1104973 ]\n",
      "   [-0.02726822 -0.67291933  0.1014236  ...  0.21196483 -0.14567767\n",
      "    -0.11049718]]]], shape=(1, 100, 2, 24), dtype=float32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-863edb684343>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_data_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-5ea17a00dcce>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-5ea17a00dcce>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'iteration: {k}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m       \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m       \u001b[0mrewards_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0mgammas_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-5ea17a00dcce>\u001b[0m in \u001b[0;36miter_func\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mlambda_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[0m\n\u001b[1;32m   1901\u001b[0m           ),\n\u001b[1;32m   1902\u001b[0m           \u001b[0minner_rank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1903\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1904\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspatial_start_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msqueeze_batch_dims\u001b[0;34m(inp, op, inner_rank, name)\u001b[0m\n\u001b[1;32m    312\u001b[0m           inp, array_ops.concat(([-1], inner_shape), axis=-1))\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mout_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mout_inner_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minner_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    936\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Computed output size would be negative: -2 [input_size: 0, effective_filter_size: 3, stride: 1] [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPzVsarRwAqM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Predictron-RUL-C-MAPSS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
