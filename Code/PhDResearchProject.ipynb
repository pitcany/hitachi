{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import norm\n",
    "import pomegranate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data and diving them into unique unit numbers\n",
    "\n",
    "We need to divide data into unique numbers, because the state restes as the unit number changes, so we need to find Gaussian distribution for different unit numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Documents/hitachi/CMAPSS/train_FD001.txt', sep=\" \", header=None)\n",
    "unique_unit_values = data[0].unique() #Number of units\n",
    "data_cycles = []\n",
    "for unit_num in unique_unit_values:\n",
    "    data_cycles.append(data[data[0] == unit_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing operational settings and normalize the data column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    x = data.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    dataNew = pd.DataFrame(x_scaled)\n",
    "    return dataNew\n",
    "#Remove the operation settings\n",
    "dataT = data[data.columns[5:26]]\n",
    "dataT.columns = range(21)\n",
    "dataT = normalize(dataT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing data for each unit\n",
    "\n",
    "I think this is why my transitional matrix previously was not working properly as in each unit the state resets and start from good condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT_cycles = []\n",
    "for unit_num in unique_unit_values:\n",
    "    dataT_cycles.append(dataT[data[0] == unit_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying and removing non variable data columns\n",
    "\n",
    "Removing the columns where the data does not vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "for dataT_cycle in dataT_cycles:\n",
    "    print(dataT_cycle.columns[dataT_cycle.std() == 0])\n",
    "\"\"\"\n",
    "Here we can see 0,4,9,15,17,18 but also 5 at many places so we drop column number 5 as well\n",
    "\"\"\"\n",
    "dataT.drop(data.columns[[0, 3, 4, 5, 9, 15, 17, 18]],axis=1,inplace=True)\n",
    "dataT.columns = range(13)\n",
    "dataT_cycles = []\n",
    "for unit_num in unique_unit_values:\n",
    "    dataT_cycles.append(dataT[data[0] == unit_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Right now only using the first data frame (i.e Machine 1) to train the VAE, but we can combine all the dataframes\n",
    "# and train the VAE jointly on the entire data for better performance \n",
    "\n",
    "x_train = dataT_cycles[0].values[:150]\n",
    "x_test = dataT_cycles[0].values[151:198]\n",
    "x_train.shape\n",
    "# x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoders to find Latent State Space Distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e2e8ac5a5bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "x_train = dataT_cycles[0].values[:100]\n",
    "x_test = dataT_cycles[0].values[101:198]\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "original_dim = x_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (original_dim, )\n",
    "intermediate_dim = 9\n",
    "batch_size = 10\n",
    "latent_dim = 5\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "# z = z_mean + sqrt(var)*eps\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    \n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9)            126         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 5)            50          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 5)            50          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 5)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 226\n",
      "Trainable params: 226\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VAE Model Encoder + Decoder \n",
    "\n",
    "# Building the Encoder\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                130       \n",
      "=================================================================\n",
      "Total params: 184\n",
      "Trainable params: 184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build decoder model \n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    help_ = \"Load h5 model trained weights\"\n",
    "    parser.add_argument(\"-w\", \"--weights\", help=help_)\n",
    "    help_ = \"Use mse loss instead of binary cross entropy (default)\"\n",
    "    parser.add_argument(\"-m\", \"--mse\", help=help_, action='store_true')\n",
    "    \n",
    "    models = (encoder, decoder)\n",
    "    data = (x_test, None)\n",
    "    \n",
    "    # VAE loss = mse_loss or xent_loss + kl_loss\n",
    "    if args.mse:\n",
    "        reconstruction_loss = mse(inputs, outputs)\n",
    "    else:\n",
    "        reconstruction_loss = binary_crossentropy(inputs, outputs)\n",
    "        \n",
    "    reconstruction_loss *= original_dim\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis= -1)\n",
    "    kl_loss *= 0.5 \n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "    vae.summary()\n",
    "    \n",
    "    if args.weights:\n",
    "        vae.load_weights(args.weights)\n",
    "    else:\n",
    "        # Train the autoencoder\n",
    "        vae.fit(x_train, epochs=epochs, batch_size= batch_size, validation_data=(x_test, None))\n",
    "        vae.save_weights('vae_mlp_CMAPSS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yannik/miniconda3/envs/ykp/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"vae_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 5), (None, 5), (N 226       \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 13)                184       \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yannik/miniconda3/envs/ykp/lib/python3.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yannik/miniconda3/envs/ykp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 100 samples, validate on 91 samples\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 8.6136 - val_loss: 7.5069\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 159us/step - loss: 8.1071 - val_loss: 6.7097\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 176us/step - loss: 7.4209 - val_loss: 5.7314\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 188us/step - loss: 6.5338 - val_loss: 4.2211\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 188us/step - loss: 5.2482 - val_loss: 2.3457\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 222us/step - loss: 3.4696 - val_loss: -0.6214\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 234us/step - loss: 0.8200 - val_loss: -4.6524\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 233us/step - loss: -3.1063 - val_loss: -10.8377\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 199us/step - loss: -8.8391 - val_loss: -20.2851\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 221us/step - loss: -17.8439 - val_loss: -35.3720\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 212us/step - loss: -32.3196 - val_loss: -61.8668\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 189us/step - loss: -57.6569 - val_loss: -110.5614\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 192us/step - loss: -103.0687 - val_loss: -209.2532\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 172us/step - loss: -193.8839 - val_loss: -428.7604\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 166us/step - loss: -395.5606 - val_loss: -973.5886\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 171us/step - loss: -876.5469 - val_loss: -2465.3963\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 164us/step - loss: -2140.9943 - val_loss: -6978.1396\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 191us/step - loss: -5912.4380 - val_loss: -21969.4612\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 168us/step - loss: -17524.6221 - val_loss: -76693.2080\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 192us/step - loss: -58330.1199 - val_loss: -299755.0117\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 175us/step - loss: -211254.3961 - val_loss: -1294789.7390\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 170us/step - loss: -824078.1781 - val_loss: -6254041.3846\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 189us/step - loss: -3874470.8000 - val_loss: -33839958.4615\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 179us/step - loss: -17673889.2000 - val_loss: -203298941.5385\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 187us/step - loss: -93301684.8000 - val_loss: -1389514401.7582\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 174us/step - loss: -575689105.6000 - val_loss: -10388783064.6154\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 190us/step - loss: -3859205760.0000 - val_loss: -91073077878.1538\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 195us/step - loss: -27723500134.4000 - val_loss: -887367626166.8572\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 191us/step - loss: -211455042355.2000 - val_loss: -9740658291363.1641\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 226us/step - loss: -1892797120512.0000 - val_loss: -123805296555919.4688\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 212us/step - loss: -17698189370982.3984 - val_loss: -1668533313927055.5000\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 233us/step - loss: -171281844115865.5938 - val_loss: -24902474047814240.0000\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 221us/step - loss: -2271257136254157.0000 - val_loss: -430710419582321728.0000\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 214us/step - loss: -30693065758448024.0000 - val_loss: -8158398050467080192.0000\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 194us/step - loss: -391592129236828160.0000 - val_loss: -168394750595001450496.0000\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 225us/step - loss: nan - val_loss: nan\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 176us/step - loss: nan - val_loss: nan\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 190us/step - loss: nan - val_loss: nan\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 177us/step - loss: nan - val_loss: nan\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 184us/step - loss: nan - val_loss: nan\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 185us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 187us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 188us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 177us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 163us/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    mse = None\n",
    "    weights = None\n",
    "    \n",
    "args = Args()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the VAE has been trained, we can use the encoder to sample the latent space\n",
    "\n",
    "#predicting the latent space for first 13 observation values for machine 1\n",
    "test = np.asarray(x_train[0:13])  \n",
    "\n",
    "# indexing on 2 because the encoder predicts z_mean, z_log_var and sampled vector z (we are interested in z only)\n",
    "latent_space = encoder.predict(test)[2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each list is a 5 dimension latent state space for that observation value\n",
    "latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the raw observation from the learned latent space \n",
    "sample = decoder.predict(latent_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18373494, 0.40680183, 0.72624799, 0.24242424, 0.109755  ,\n",
       "       0.36904762, 0.63326226, 0.20588235, 0.1996078 , 0.36398615,\n",
       "       0.33333333, 0.71317829, 0.7246617 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the with the real x_train value\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Right now they are not same as we trained the VAE on very less amount of data \n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using HMM to find out transitional matrices\n",
    "\n",
    "Here we first define transmatrix as [[0.5, 0.5, 0.0, 0.0],[0.0, 0.4, 0.6, 0.0],[0.0, 0.0, 0.3, 0.7],[0.0,0.0,0.0,1.0]] which means there is half chance for each state to go to next state and half to remain in the current state itself when fully healthy, 0.4 probability of remaining at current state when at 'above average' health, 0.3 probability when 'below average', and with certainty to stay at a failing state if already failing.\n",
    "\n",
    "Then we train for each unit for transmatrix as well as state means and we will take average of each unit transmatrices and states as the transmatrix and state\n",
    "\n",
    "*Note*: Here state '0' means the perfect health and '3' means weakest health "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.726248</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.109755</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.633262</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.628019</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.140043</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.149960</td>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.683235</td>\n",
       "      <td>0.336554</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.072602</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.234542</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.091599</td>\n",
       "      <td>0.753367</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.286822</td>\n",
       "      <td>0.089202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.894578</td>\n",
       "      <td>0.547853</td>\n",
       "      <td>0.136876</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.102396</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.189765</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.090670</td>\n",
       "      <td>0.744132</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.301712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.731928</td>\n",
       "      <td>0.614345</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.084582</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.287846</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.065229</td>\n",
       "      <td>0.759523</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>0.239299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.641566</td>\n",
       "      <td>0.682799</td>\n",
       "      <td>0.172303</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.094364</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.187633</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.075704</td>\n",
       "      <td>0.740669</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.240310</td>\n",
       "      <td>0.324910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.701807</td>\n",
       "      <td>0.662089</td>\n",
       "      <td>0.225443</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.051557</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.296375</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.056714</td>\n",
       "      <td>0.717199</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.097625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.183735  0.406802  0.726248  0.242424  0.109755  0.369048  0.633262   \n",
       "1    0.283133  0.453019  0.628019  0.212121  0.100242  0.380952  0.765458   \n",
       "2    0.343373  0.369523  0.710145  0.272727  0.140043  0.250000  0.795309   \n",
       "3    0.343373  0.256159  0.740741  0.318182  0.124518  0.166667  0.889126   \n",
       "4    0.349398  0.257467  0.668277  0.242424  0.149960  0.255952  0.746269   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "187  0.765060  0.683235  0.336554  0.621212  0.072602  0.684524  0.234542   \n",
       "188  0.894578  0.547853  0.136876  0.560606  0.102396  0.732143  0.189765   \n",
       "189  0.731928  0.614345  0.231884  0.590909  0.084582  0.880952  0.287846   \n",
       "190  0.641566  0.682799  0.172303  0.575758  0.094364  0.773810  0.187633   \n",
       "191  0.701807  0.662089  0.225443  0.636364  0.051557  0.833333  0.296375   \n",
       "\n",
       "            7         8         9        10        11        12  \n",
       "0    0.205882  0.199608  0.363986  0.333333  0.713178  0.724662  \n",
       "1    0.279412  0.162813  0.411312  0.333333  0.666667  0.731014  \n",
       "2    0.220588  0.171793  0.357445  0.166667  0.627907  0.621375  \n",
       "3    0.294118  0.174889  0.166603  0.333333  0.573643  0.662386  \n",
       "4    0.235294  0.174734  0.402078  0.416667  0.589147  0.704502  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "187  0.514706  0.091599  0.753367  0.666667  0.286822  0.089202  \n",
       "188  0.661765  0.090670  0.744132  0.583333  0.263566  0.301712  \n",
       "189  0.691176  0.065229  0.759523  0.833333  0.271318  0.239299  \n",
       "190  0.617647  0.075704  0.740669  0.500000  0.240310  0.324910  \n",
       "191  0.647059  0.056714  0.717199  0.666667  0.263566  0.097625  \n",
       "\n",
       "[192 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataT_cycles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\",init_params=\"cm\", params=\"mtc\")\n",
    "lr.startprob_ = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "transmats = []\n",
    "statemeans = []\n",
    "covars = []\n",
    "for i in range(100):\n",
    "    lr.transmat_ = np.array([[0.5, 0.5, 0.0, 0.0],[0.0, 0.4, 0.6, 0.0],[0.0, 0.0, 0.3, 0.7],[0.0,0.0,0.0,1.0]])\n",
    "    lr.fit(dataT_cycles[i])\n",
    "    transmats.append(lr.transmat_)\n",
    "    statemeans.append(lr.means_)\n",
    "    covars.append(lr.covars_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = hmm.GMMHMM(n_components=4, n_mix=4, covariance_type=\"diag\",init_params=\"cm\", params=\"mt\")\n",
    "#lr.startprob_ = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "#transmats = []\n",
    "#statemeans = []\n",
    "#for i in range(100):\n",
    "#    lr.transmat_ = np.array([[0.5, 0.5, 0.0, 0.0],[0.0, 0.5, 0.5, 0.0],[0.0, 0.0, 0.5, 0.5],[0.0,0.0,0.0,1.0]])\n",
    "#    lr.fit(dataT_cycles[i])\n",
    "#    transmat = lr.transmat_\n",
    "#    transmats.append(transmat)\n",
    "#    statemeans.append(lr.means_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transmat = np.array(transmats).mean(axis=0)\n",
    "statemean = np.array(statemeans).mean(axis=0)\n",
    "covar = np.array(covars).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59505558, 0.40494442, 0.        , 0.        ],\n",
       "       [0.        , 0.76482211, 0.23517789, 0.        ],\n",
       "       [0.        , 0.        , 0.88093494, 0.11906506],\n",
       "       [0.        , 0.        , 0.        , 0.98      ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.595056</td>\n",
       "      <td>0.404944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764822</td>\n",
       "      <td>0.235178</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880935</td>\n",
       "      <td>0.119065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.595056  0.404944  0.000000  0.000000\n",
       "1  0.000000  0.764822  0.235178  0.000000\n",
       "2  0.000000  0.000000  0.880935  0.119065\n",
       "3  0.000000  0.000000  0.000000  0.980000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.361872</td>\n",
       "      <td>0.358909</td>\n",
       "      <td>0.649480</td>\n",
       "      <td>0.250338</td>\n",
       "      <td>0.159575</td>\n",
       "      <td>0.319248</td>\n",
       "      <td>0.673117</td>\n",
       "      <td>0.270409</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.383784</td>\n",
       "      <td>0.363723</td>\n",
       "      <td>0.599998</td>\n",
       "      <td>0.627357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.432294</td>\n",
       "      <td>0.555328</td>\n",
       "      <td>0.302983</td>\n",
       "      <td>0.188051</td>\n",
       "      <td>0.422327</td>\n",
       "      <td>0.574544</td>\n",
       "      <td>0.327012</td>\n",
       "      <td>0.216596</td>\n",
       "      <td>0.462189</td>\n",
       "      <td>0.440688</td>\n",
       "      <td>0.513007</td>\n",
       "      <td>0.535993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.566330</td>\n",
       "      <td>0.537478</td>\n",
       "      <td>0.434005</td>\n",
       "      <td>0.378785</td>\n",
       "      <td>0.241778</td>\n",
       "      <td>0.567415</td>\n",
       "      <td>0.431069</td>\n",
       "      <td>0.399449</td>\n",
       "      <td>0.259748</td>\n",
       "      <td>0.582052</td>\n",
       "      <td>0.541015</td>\n",
       "      <td>0.402448</td>\n",
       "      <td>0.411874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.700865</td>\n",
       "      <td>0.638011</td>\n",
       "      <td>0.308127</td>\n",
       "      <td>0.475684</td>\n",
       "      <td>0.310537</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>0.284764</td>\n",
       "      <td>0.494123</td>\n",
       "      <td>0.319494</td>\n",
       "      <td>0.704721</td>\n",
       "      <td>0.656289</td>\n",
       "      <td>0.275199</td>\n",
       "      <td>0.283998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.361872  0.358909  0.649480  0.250338  0.159575  0.319248  0.673117   \n",
       "1  0.447684  0.432294  0.555328  0.302983  0.188051  0.422327  0.574544   \n",
       "2  0.566330  0.537478  0.434005  0.378785  0.241778  0.567415  0.431069   \n",
       "3  0.700865  0.638011  0.308127  0.475684  0.310537  0.720825  0.284764   \n",
       "\n",
       "          7         8         9        10        11        12  \n",
       "0  0.270409  0.197400  0.383784  0.363723  0.599998  0.627357  \n",
       "1  0.327012  0.216596  0.462189  0.440688  0.513007  0.535993  \n",
       "2  0.399449  0.259748  0.582052  0.541015  0.402448  0.411874  \n",
       "3  0.494123  0.319494  0.704721  0.656289  0.275199  0.283998  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(statemean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_prob = np.array([transmat, transmat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array([[100, 50, 0, -50],[-50, 0, 50, 100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-50</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2    3\n",
       "0  100  50   0  -50\n",
       "1  -50   0  50  100"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.374788</td>\n",
       "      <td>0.376223</td>\n",
       "      <td>0.324514</td>\n",
       "      <td>0.387588</td>\n",
       "      <td>0.394292</td>\n",
       "      <td>0.381208</td>\n",
       "      <td>0.320688</td>\n",
       "      <td>0.385311</td>\n",
       "      <td>0.391740</td>\n",
       "      <td>0.372861</td>\n",
       "      <td>0.374594</td>\n",
       "      <td>0.335262</td>\n",
       "      <td>0.329673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.364689</td>\n",
       "      <td>0.368252</td>\n",
       "      <td>0.336731</td>\n",
       "      <td>0.383089</td>\n",
       "      <td>0.392593</td>\n",
       "      <td>0.370781</td>\n",
       "      <td>0.335680</td>\n",
       "      <td>0.381324</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.363984</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.346336</td>\n",
       "      <td>0.341720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.350527</td>\n",
       "      <td>0.354387</td>\n",
       "      <td>0.354969</td>\n",
       "      <td>0.375980</td>\n",
       "      <td>0.388699</td>\n",
       "      <td>0.352671</td>\n",
       "      <td>0.354949</td>\n",
       "      <td>0.373650</td>\n",
       "      <td>0.386448</td>\n",
       "      <td>0.347917</td>\n",
       "      <td>0.352987</td>\n",
       "      <td>0.361741</td>\n",
       "      <td>0.359971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.322227</td>\n",
       "      <td>0.331848</td>\n",
       "      <td>0.377370</td>\n",
       "      <td>0.361736</td>\n",
       "      <td>0.381070</td>\n",
       "      <td>0.318619</td>\n",
       "      <td>0.379061</td>\n",
       "      <td>0.358460</td>\n",
       "      <td>0.379796</td>\n",
       "      <td>0.318186</td>\n",
       "      <td>0.329709</td>\n",
       "      <td>0.381543</td>\n",
       "      <td>0.380118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.374788  0.376223  0.324514  0.387588  0.394292  0.381208  0.320688   \n",
       "1  0.364689  0.368252  0.336731  0.383089  0.392593  0.370781  0.335680   \n",
       "2  0.350527  0.354387  0.354969  0.375980  0.388699  0.352671  0.354949   \n",
       "3  0.322227  0.331848  0.377370  0.361736  0.381070  0.318619  0.379061   \n",
       "\n",
       "          7         8         9        10        11        12  \n",
       "0  0.385311  0.391740  0.372861  0.374594  0.335262  0.329673  \n",
       "1  0.381324  0.390411  0.363984  0.365500  0.346336  0.341720  \n",
       "2  0.373650  0.386448  0.347917  0.352987  0.361741  0.359971  \n",
       "3  0.358460  0.379796  0.318186  0.329709  0.381543  0.380118  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(e_prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00938058, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.00884829, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.00721507, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.00590842, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.00490603,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00717607, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00726753, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.00587392, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.00484224, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.00816436,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.008276  , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00820073, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.00868872]],\n",
       "\n",
       "       [[0.00956401, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.00902801, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.00672983, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.00479253, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.00371094,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.0066657 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00683626, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.00480184, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.003609  , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.00792578,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00803304, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00772703, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.00870992]],\n",
       "\n",
       "       [[0.00981864, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.00893287, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.00658029, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.00425062, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.00344104,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00669142, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00703067, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.00423336, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.00323317, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.00787979,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00825487, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00794689, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.00878466]],\n",
       "\n",
       "       [[0.01092566, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.00973272, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.00782515, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.0052074 , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.00320405,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00877202, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00868967, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.00503661, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.00301433, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.00912092,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.0087724 , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00938188, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01019947]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar=[covar[i].sum(axis=1) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.008689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>0.008710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.008785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.010199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.009381  0.008848  0.007215  0.005908  0.004906  0.007176  0.007268   \n",
       "1  0.009564  0.009028  0.006730  0.004793  0.003711  0.006666  0.006836   \n",
       "2  0.009819  0.008933  0.006580  0.004251  0.003441  0.006691  0.007031   \n",
       "3  0.010926  0.009733  0.007825  0.005207  0.003204  0.008772  0.008690   \n",
       "\n",
       "          7         8         9        10        11        12  \n",
       "0  0.005874  0.004842  0.008164  0.008276  0.008201  0.008689  \n",
       "1  0.004802  0.003609  0.007926  0.008033  0.007727  0.008710  \n",
       "2  0.004233  0.003233  0.007880  0.008255  0.007947  0.008785  \n",
       "3  0.005037  0.003014  0.009121  0.008772  0.009382  0.010199  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prob = np.array([norm.pdf(statemean,covar), norm.pdf(statemean,covar)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.37478796, 0.37622323, 0.32451365, 0.38758829, 0.39429238,\n",
       "         0.38120786, 0.32068759, 0.3853114 , 0.39173988, 0.37286105,\n",
       "         0.37459408, 0.33526193, 0.32967326],\n",
       "        [0.36468882, 0.36825229, 0.3367309 , 0.38308862, 0.39259275,\n",
       "         0.37078129, 0.33568006, 0.3813236 , 0.39041098, 0.36398436,\n",
       "         0.36549971, 0.34633639, 0.34171987],\n",
       "        [0.35052656, 0.35438711, 0.35496939, 0.3759799 , 0.388699  ,\n",
       "         0.35267102, 0.35494918, 0.37365004, 0.38644814, 0.34791691,\n",
       "         0.35298654, 0.36174134, 0.35997111],\n",
       "        [0.3222267 , 0.33184765, 0.37737027, 0.36173636, 0.3810701 ,\n",
       "         0.31861851, 0.37906054, 0.35845975, 0.37979588, 0.31818635,\n",
       "         0.32970924, 0.38154338, 0.38011795]],\n",
       "\n",
       "       [[0.37478796, 0.37622323, 0.32451365, 0.38758829, 0.39429238,\n",
       "         0.38120786, 0.32068759, 0.3853114 , 0.39173988, 0.37286105,\n",
       "         0.37459408, 0.33526193, 0.32967326],\n",
       "        [0.36468882, 0.36825229, 0.3367309 , 0.38308862, 0.39259275,\n",
       "         0.37078129, 0.33568006, 0.3813236 , 0.39041098, 0.36398436,\n",
       "         0.36549971, 0.34633639, 0.34171987],\n",
       "        [0.35052656, 0.35438711, 0.35496939, 0.3759799 , 0.388699  ,\n",
       "         0.35267102, 0.35494918, 0.37365004, 0.38644814, 0.34791691,\n",
       "         0.35298654, 0.36174134, 0.35997111],\n",
       "        [0.3222267 , 0.33184765, 0.37737027, 0.36173636, 0.3810701 ,\n",
       "         0.31861851, 0.37906054, 0.35845975, 0.37979588, 0.31818635,\n",
       "         0.32970924, 0.38154338, 0.38011795]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: no-repair, 1: repair\n",
    "actions = ('0', '1')\n",
    "# 0: failing, 1: low health, 2: good health, 3: perfect health\n",
    "states = ('0', '1', '2', '3')\n",
    "\n",
    "discount = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First we define an MDP. We also represent a policy\n",
    "as a dictionary of {state: action} pairs, and a utility function as a\n",
    "dictionary of {state: number} pairs. We then define the value_iteration\n",
    "and policy_iteration algorithms.\"\"\"\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class MDP:\n",
    "\n",
    "    \"\"\"A Markov Decision Process, defined by an initial state, transition model,\n",
    "    and reward function. We also keep track of a gamma value, for use by\n",
    "    algorithms. The transition model is represented somewhat differently from\n",
    "    the text. Instead of P(s' | s, a) being a probability number for each\n",
    "    state/state/action triplet, we instead have T(s, a) return a\n",
    "    list of (p, s') pairs. We also keep track of the possible states,\n",
    "    terminal states, and actions for each state.\"\"\"\n",
    "\n",
    "    def __init__(self, init, actlist, terminals, transitions=None, reward=None, states=None, discount=0.9):\n",
    "        if not (0 < discount <= 1):\n",
    "            raise ValueError(\"An MDP must have 0 < discount <= 1\")\n",
    "\n",
    "        # collect states from transitions table if not passed.\n",
    "        self.states = states or self.get_states_from_transitions(transitions)\n",
    "            \n",
    "        self.init = init\n",
    "        \n",
    "        if isinstance(actlist, list):\n",
    "            # if actlist is a list, all states have the same actions\n",
    "            self.actlist = actlist\n",
    "\n",
    "        elif isinstance(actlist, dict):\n",
    "            # if actlist is a dict, different actions for each state\n",
    "            self.actlist = actlist\n",
    "        \n",
    "        self.terminals = terminals\n",
    "        self.transitions = transitions or {}\n",
    "        if not self.transitions:\n",
    "            print(\"Warning: Transition table is empty.\")\n",
    "            \n",
    "        self.discount = discount\n",
    "        \n",
    "        # maybe I should change this\n",
    "        # self.gamma = gamma\n",
    "\n",
    "        self.reward = reward or {s: 0 for s in self.states}\n",
    "\n",
    "        # self.check_consistency()\n",
    "\n",
    "    def R(self, state):\n",
    "        \"\"\"Return a numeric reward for this state.\"\"\"\n",
    "\n",
    "        return self.reward[state]\n",
    "\n",
    "    def T(self, state, action):\n",
    "        \"\"\"Transition model. From a state and an action, return a list\n",
    "        of (probability, result-state) pairs.\"\"\"\n",
    "\n",
    "        if not self.transitions:\n",
    "            raise ValueError(\"Transition model is missing\")\n",
    "        else:\n",
    "            return self.transitions[state][action]\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"Return a list of actions that can be performed in this state. By default, a\n",
    "        fixed list of actions, except for terminal states. Override this\n",
    "        method if you need to specialize by state.\"\"\"\n",
    "\n",
    "        if state in self.terminals:\n",
    "            return [None]\n",
    "        else:\n",
    "            return self.actlist\n",
    "\n",
    "    def get_states_from_transitions(self, transitions):\n",
    "        if isinstance(transitions, dict):\n",
    "            s1 = set(transitions.keys())\n",
    "            s2 = set(tr[1] for actions in transitions.values()\n",
    "                     for effects in actions.values()\n",
    "                     for tr in effects)\n",
    "            return s1.union(s2)\n",
    "        else:\n",
    "            print('Could not retrieve states from transitions')\n",
    "            return None\n",
    "\n",
    "    def check_consistency(self):\n",
    "\n",
    "        # check that all states in transitions are valid\n",
    "        assert set(self.states) == self.get_states_from_transitions(self.transitions)\n",
    "\n",
    "        # check that init is a valid state\n",
    "        assert self.init in self.states\n",
    "\n",
    "        # check reward for each state\n",
    "        assert set(self.reward.keys()) == set(self.states)\n",
    "\n",
    "        # check that all terminals are valid states\n",
    "        assert all(t in self.states for t in self.terminals)\n",
    "\n",
    "        # check that probability distributions for all actions sum to 1\n",
    "        for s1, actions in self.transitions.items():\n",
    "            for a in actions.keys():\n",
    "                s = 0\n",
    "                for o in actions[a]:\n",
    "                    s += o[0]\n",
    "                assert abs(s - 1) < 0.001\n",
    "\n",
    "class POMDP(MDP):\n",
    "\n",
    "    \"\"\"A Partially Observable Markov Decision Process, defined by\n",
    "    a transition model P(s'|s,a), actions A(s), a reward function R(s),\n",
    "    and a sensor model P(e|s). We also keep track of a gamma value,\n",
    "    for use by algorithms. The transition and the sensor models\n",
    "    are defined as matrices. We also keep track of the possible states\n",
    "    and actions for each state.\"\"\"\n",
    "\n",
    "    def __init__(self, actions, transitions=None, evidences=None, rewards=None, states=None, discount=0.95):\n",
    "        \"\"\"Initialize variables of the pomdp\"\"\"\n",
    "\n",
    "        if not (0 < discount <= 1):\n",
    "            raise ValueError('A POMDP must have 0 < discount <= 1')\n",
    "\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "\n",
    "        # transition model cannot be undefined\n",
    "        self.t_prob = transitions\n",
    "        if not self.t_prob.any():\n",
    "            print('Warning: Transition model is undefined')\n",
    "        \n",
    "        # sensor model cannot be undefined\n",
    "        self.e_prob = evidences\n",
    "        if not self.e_prob.any():\n",
    "            print('Warning: Sensor model is undefined')\n",
    "        \n",
    "        self.discount = discount\n",
    "        # may have to change this\n",
    "        # self.gamma = gamma\n",
    "        self.rewards = rewards\n",
    "        \n",
    "class Matrix:\n",
    "    \"\"\"Matrix operations class\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def add(A, B):\n",
    "        \"\"\"Add two matrices A and B\"\"\"\n",
    "\n",
    "        res = []\n",
    "        for i in range(len(A)):\n",
    "            row = []\n",
    "            for j in range(len(A[0])):\n",
    "                row.append(A[i][j] + B[i][j])\n",
    "            res.append(row)\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def scalar_multiply(a, B):\n",
    "        \"\"\"Multiply scalar a to matrix B\"\"\"\n",
    "\n",
    "        for i in range(len(B)):\n",
    "            for j in range(len(B[0])):\n",
    "                B[i][j] = a * B[i][j]\n",
    "        return B\n",
    "\n",
    "    @staticmethod\n",
    "    def multiply(A, B):\n",
    "        \"\"\"Multiply two matrices A and B element-wise\"\"\"\n",
    "\n",
    "        matrix = []\n",
    "        for i in range(len(B)):\n",
    "            row = []\n",
    "            for j in range(len(B[0])):\n",
    "                row.append(B[i][j] * A[j][i])\n",
    "            matrix.append(row)\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def matmul(A, B):\n",
    "        \"\"\"Inner-product of two matrices\"\"\"\n",
    "\n",
    "        return [[sum(ele_a*ele_b for ele_a, ele_b in zip(row_a, col_b)) for col_b in list(zip(*B))] for row_a in A]\n",
    "\n",
    "    @staticmethod\n",
    "    def transpose(A):\n",
    "        \"\"\"Transpose a matrix\"\"\"\n",
    "        \n",
    "        return [list(i) for i in zip(*A)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving POMDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaVector:\n",
    "    \"\"\"\n",
    "    Simple wrapper for an alpha vector, used for representing the value function for a POMDP as a piecewise-linear,\n",
    "    convex function\n",
    "    \"\"\"\n",
    "    def __init__(self, a, v):\n",
    "        self.action = a\n",
    "        self.v = v\n",
    "\n",
    "    def copy(self):\n",
    "        return AlphaVector(self.action, self.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration:\n",
    "    def __init__(self, pomdp):\n",
    "        \"\"\"\n",
    "        Initialize the POMDP exact value iteration solver\n",
    "        :param agent:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.model = pomdp\n",
    "        self.gamma = set()\n",
    "\n",
    "    def value_iteration(self, horizon):\n",
    "        \"\"\"\n",
    "        Solve the POMDP by computing all alpha vectors\n",
    "        :param t: transition probability matrix\n",
    "        :param o: observation probability matrix\n",
    "        :param r: immediate rewards matrix\n",
    "        :param horizon: integer valued scalar represented the number of planning steps\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        t = self.model.t_prob\n",
    "        o = self.model.e_prob\n",
    "        r = self.model.reward\n",
    "        # the above three are used later--important\n",
    "        discount = self.model.discount\n",
    "        actions = len(self.model.actions)  # |A| actions\n",
    "        states = len(self.model.states)  # |S| states\n",
    "        # I might need to change this\n",
    "        observations = len(self.model.get_all_observations())  # |Z| observations\n",
    "        first = True\n",
    "\n",
    "        # initialize gamma with a 0 alpha-vector\n",
    "        dummy = AlphaVector(a=-1, v=np.zeros(states))\n",
    "        self.gamma.add(dummy)\n",
    "\n",
    "        # start with 1 step planning horizon, up to horizon-length planning horizon\n",
    "        for k in range(horizon):\n",
    "            print('[Value Iteration] planning horizon {}...'.format(k))\n",
    "            # new set of alpha vectors to add to set gamma\n",
    "            gamma_k = set()\n",
    "            # Compute the new coefficients for the new alpha-vectors\n",
    "            v_new = np.zeros(shape=(len(self.gamma), actions, observations, states))\n",
    "            idx = 0\n",
    "            for v in self.gamma:\n",
    "                for u in range(actions):\n",
    "                    for z in range(observations):\n",
    "                        for j in range(states):\n",
    "                            for i in range(states):\n",
    "                                # v_i_k * p(z | x_i, u) * p(x_i | u, x_j)\n",
    "                                v_new[idx][u][z][i] += v.v[i] * o[u][i][z] * t[u][j][i]\n",
    "                idx += 1\n",
    "            # add (|A| * |V|^|Z|) alpha-vectors to gamma, |V| is |gamma_k|\n",
    "            for u in range(actions):\n",
    "                c = self.compute_indices(idx, observations)\n",
    "                for indices in c:  # n elements in c is |V|^|Z|\n",
    "                    for z in range(observations):\n",
    "                        temp = np.zeros(states)\n",
    "                        for i in range(states):\n",
    "                            temp[i] = discount * (r[u][i] + v_new[indices[z]][u][z][i])\n",
    "                        gamma_k.add(AlphaVector(a=u, v=temp))\n",
    "            self.gamma.update(gamma_k)\n",
    "            if first:\n",
    "                # remove the dummy alpha vector\n",
    "                self.gamma.remove(dummy)\n",
    "                first = False\n",
    "            self.prune(states)\n",
    "            #  plot_gamma(title='V(b) for horizon T = ' + str(k + 1), self.gamma)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_indices(k, m):\n",
    "        \"\"\"\n",
    "        Compute all orderings of m elements with values between [0, k-1]\n",
    "        :param k: Number of alpha-vectors\n",
    "        :param m: Number of observations\n",
    "        :return: list of lists, where each list contains m elements, and each element is in [0, k-1].\n",
    "        Total should be k^m elements\n",
    "        \"\"\"\n",
    "        x = list(range(k))\n",
    "        return [p for p in product(x, repeat=m)]\n",
    "\n",
    "    def prune(self, n_states):\n",
    "        \"\"\"\n",
    "        Remove dominated alpha-vectors using Lark's filtering algorithm\n",
    "        :param n_states\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # parameters for linear program\n",
    "        delta = 0.0000000001\n",
    "        # equality constraints on the belief states\n",
    "        A_eq = np.array([np.append(np.ones(n_states), [0.])])\n",
    "        b_eq = np.array([1.])\n",
    "\n",
    "        # dirty set\n",
    "        F = self.gamma.copy()\n",
    "        # clean set\n",
    "        Q = set()\n",
    "\n",
    "        for i in range(n_states):\n",
    "            max_i = -np.inf\n",
    "            best = None\n",
    "            for av in F:\n",
    "                if av.v[i] > max_i:\n",
    "                    max_i = av.v[i]\n",
    "                    best = av\n",
    "            Q.update({best})\n",
    "            F.remove(best)\n",
    "        while F:\n",
    "            av_i = F.pop()  # get a reference to av_i\n",
    "            F.add(av_i)  # don't want to remove it yet from F\n",
    "            dominated = False\n",
    "            for av_j in Q:\n",
    "                c = np.append(np.zeros(n_states), [1.])\n",
    "                A_ub = np.array([np.append(-(av_i.v - av_j.v), [-1.])])\n",
    "                b_ub = np.array([-delta])\n",
    "\n",
    "                res = linprog(c, A_eq=A_eq, b_eq=b_eq, A_ub=A_ub, b_ub=b_ub, bounds=(0, None))\n",
    "                if res.x[n_states] > 0.0:\n",
    "                    # this one is dominated\n",
    "                    dominated = True\n",
    "                    F.remove(av_i)\n",
    "                    break\n",
    "\n",
    "            if not dominated:\n",
    "                max_k = -np.inf\n",
    "                best = None\n",
    "                for av_k in F:\n",
    "                    b = res.x[0:2]\n",
    "                    v = np.dot(av_k.v, b)\n",
    "                    if v > max_k:\n",
    "                        max_k = v\n",
    "                        best = av_k\n",
    "                F.remove(best)\n",
    "                if not self.check_duplicate(Q, best):\n",
    "                    Q.update({best})\n",
    "        self.gamma = Q\n",
    "\n",
    "    @staticmethod\n",
    "    def check_duplicate(a, av):\n",
    "        \"\"\"\n",
    "        Check whether alpha vector av is already in set a\n",
    "\n",
    "        :param a:\n",
    "        :param av:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for av_i in a:\n",
    "            if np.allclose(av_i.v, av.v):\n",
    "                return True\n",
    "            if av_i.v[0] == av.v[0] and av_i.v[1] > av.v[1]:\n",
    "                return True\n",
    "            if av_i.v[1] == av.v[1] and av_i.v[0] > av.v[0]:\n",
    "                return True\n",
    "\n",
    "    @staticmethod\n",
    "    def select_action(belief, vector_set):\n",
    "        \"\"\"\n",
    "        Compute optimal action given a belief distribution\n",
    "        :param belief: dim(belief) == dim(AlphaVector)\n",
    "        :param vector_set\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        max_v = -np.inf\n",
    "        best = None\n",
    "        for av in vector_set:\n",
    "            v = np.dot(av.v, belief)\n",
    "\n",
    "            if v > max_v:\n",
    "                max_v = v\n",
    "                best = av\n",
    "\n",
    "        if best is None:\n",
    "            raise ValueError('Vector set should not be empty')\n",
    "\n",
    "        return best.action, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', '1', '2', '3')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pomdp = POMDP(actions, t_prob, e_prob, rewards, states, discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp_solve = ValueIteration(pomdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'0': [array([ 219.62145794,   87.04320423,  -58.95578452, -185.0924472 ])]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility = pomdp_value_iteration(pomdp, epsilon=3)\n",
    "utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>204.525160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>88.982036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-34.290243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-171.265281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  204.525160\n",
       "1   88.982036\n",
       "2  -34.290243\n",
       "3 -171.265281"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([204.52516018,   88.9820356 ,  -34.29024281, -171.26528113]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADQRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These lines establish the feed-forward part of the network used to choose actions\n",
    "inputs1 = tf.placeholder(shape=[1,13],dtype=tf.float32)\n",
    "W = tf.Variable(tf.random_uniform([13,2],0,0.01))\n",
    "Qout = tf.matmul(inputs1,W)\n",
    "predict = tf.argmax(Qout,1)\n",
    "\n",
    "#Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "nextQ = tf.placeholder(shape=[1,2],dtype=tf.float32)\n",
    "loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "updateModel = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(obs):\n",
    "    state = 0\n",
    "    diff = 16\n",
    "    for i in range(len(statemean)):\n",
    "        stateDiff = obs - statemean[i]\n",
    "        stateDiffVal = np.sqrt(np.mean(stateDiff**2))\n",
    "        if stateDiffVal < diff:\n",
    "            diff = stateDiffVal\n",
    "            state = i\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the next step after an action is done\n",
    "\n",
    "def getStepDetails(i,j,action):\n",
    "    unitData = dataT_cycles[i]\n",
    "    d = False\n",
    "    if action == 1:\n",
    "        newJ = 0\n",
    "    else:\n",
    "        newJ = j+1\n",
    "    obsNext = unitData.values[newJ]\n",
    "    if newJ >= len(unitData) - 1:\n",
    "        d = True\n",
    "    s1 = get_state(obsNext)\n",
    "    r1 = rewards[action][s1]\n",
    "    return r1,newJ,s1,obsNext,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set learning parameters\n",
    "init = tf.global_variables_initializer()\n",
    "y = discount\n",
    "e = 0.1\n",
    "num_episodes = len(dataT_cycles)\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "D = np.empty([0,5]) # Replay memory\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        #Reset environment and get first new observation for new unit\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        k = 0\n",
    "        unitData = dataT_cycles[i]\n",
    "        #The Q-Network\n",
    "        while j < len(unitData):\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            a,allQ = sess.run([predict,Qout],feed_dict={inputs1:unitData.values[j].reshape(1,13)})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = np.random.randint(0,2)\n",
    "            #Get new state and reward from environment\n",
    "            r,j,s1,o1,d = getStepDetails(i,j,a[0])\n",
    "            D = np.vstack([D, [a[0],unitData.values[j-1].reshape(1,13),r,o1,s1]])\n",
    "            if len(D) > 20:\n",
    "                lastInd = np.random.randint(15,len(D))\n",
    "                randomSample = D[lastInd-15:lastInd]\n",
    "                finalO = D[lastInd,3].reshape(1,13)\n",
    "                Reward = np.sum(D[lastInd-15:lastInd,2])\n",
    "            else:\n",
    "                finalO = o1.reshape(1,13)\n",
    "                Reward = r\n",
    "            # We take batch size of 15 (j in algorithm)\n",
    "            #Obtain the Q' values by feeding the new state through our network\n",
    "            Q1 = sess.run(Qout,feed_dict={inputs1:finalO})\n",
    "            #Obtain maxQ' and set our target value for chosen action.\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0,a[0]] = Reward + y*maxQ1\n",
    "            #Train our network using target and predicted Q values\n",
    "            _,W1 = sess.run([updateModel,W],feed_dict={inputs1:unitData.values[j-1].reshape(1,13),nextQ:targetQ})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            k += 1\n",
    "            if d == True or k >= 1000:\n",
    "                #Reduce chance of random action as we train the model.\n",
    "                e = 1./((i/50) + 10)\n",
    "                break\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataT_cycles[5].values[160].reshape(-1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77108434, 0.48484848, 0.40257649, 0.51515152, 0.03688414,\n",
       "       0.61904762, 0.36886994, 0.55882353, 0.03333677, 0.65101962,\n",
       "       0.58333333, 0.30232558, 0.2903894 ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataT_cycles[5].values[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2364.409  , 5880.967  ],\n",
       "       [1871.21   , 5603.3594 ],\n",
       "       [3616.782  , 4988.657  ],\n",
       "       [4809.125  ,  873.2698 ],\n",
       "       [3126.0398 ,   76.49012],\n",
       "       [3813.273  , 3731.947  ],\n",
       "       [5509.8306 , 1830.7938 ],\n",
       "       [4643.098  ,  543.59045],\n",
       "       [8576.893  ,  -95.22542],\n",
       "       [2755.4534 , 2314.9817 ],\n",
       "       [2022.7578 , 2662.1064 ],\n",
       "       [4247.6187 , 1322.4498 ],\n",
       "       [2997.3079 , 1125.1122 ]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19181.12600722, 16785.20466186]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate that my modified HMM approach does well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "startprob = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "# The transition matrix\n",
    "transmat = np.array([[0.5, 0.5, 0.        , 0.        ],\n",
    "       [0.        , 0.7, 0.3, 0.        ],\n",
    "       [0.        , 0.        , 0.7, 0.3],\n",
    "       [0.        , 0.        , 0.        , 1.        ]])\n",
    "# The means of each component\n",
    "means = np.array([[0.0],\n",
    "                  [2.0],\n",
    "                  [4.0],\n",
    "                  [6.0]])\n",
    "# The covariance of each component\n",
    "covars = .5 * np.tile(np.identity(1), (4, 1, 1))\n",
    "\n",
    "# Build an HMM instance and set parameters\n",
    "model = hmm.GaussianHMM(n_components=4, covariance_type=\"full\")\n",
    "\n",
    "# Instead of fitting it from the data, we directly set the estimated\n",
    "# parameters, the means and covariance of the components\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.means_ = means\n",
    "model.covars_ = covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "X, Z = model.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78741127],\n",
       "       [-0.85468068],\n",
       "       [ 1.92227986],\n",
       "       [ 2.57110241],\n",
       "       [ 2.34802956],\n",
       "       [ 4.40175357],\n",
       "       [ 6.47569351],\n",
       "       [ 5.92391523],\n",
       "       [ 5.61234941],\n",
       "       [ 5.56644978],\n",
       "       [ 5.87304739],\n",
       "       [ 5.41978284],\n",
       "       [ 5.81959748],\n",
       "       [ 6.03645575],\n",
       "       [ 6.41476863],\n",
       "       [ 5.9034605 ],\n",
       "       [ 6.3667654 ],\n",
       "       [ 6.18113468],\n",
       "       [ 5.13432466],\n",
       "       [ 4.68990348],\n",
       "       [ 5.43503211],\n",
       "       [ 5.35102728],\n",
       "       [ 5.72685409],\n",
       "       [ 4.77774061],\n",
       "       [ 6.58361492],\n",
       "       [ 4.89415055],\n",
       "       [ 6.24063154],\n",
       "       [ 5.80958982],\n",
       "       [ 5.1522272 ],\n",
       "       [ 6.66697103],\n",
       "       [ 6.1722104 ],\n",
       "       [ 4.83741061],\n",
       "       [ 5.93581895],\n",
       "       [ 5.97718146],\n",
       "       [ 6.20925034],\n",
       "       [ 5.96357562],\n",
       "       [ 7.08130902],\n",
       "       [ 6.01362725],\n",
       "       [ 4.9751615 ],\n",
       "       [ 5.22894194],\n",
       "       [ 5.78982243],\n",
       "       [ 5.68638644],\n",
       "       [ 6.10442263],\n",
       "       [ 6.715448  ],\n",
       "       [ 5.96245544],\n",
       "       [ 6.36789792],\n",
       "       [ 6.67615837],\n",
       "       [ 5.775979  ],\n",
       "       [ 6.17207202],\n",
       "       [ 6.10490675],\n",
       "       [ 6.21752497],\n",
       "       [ 6.47223947],\n",
       "       [ 6.48827898],\n",
       "       [ 6.60880508],\n",
       "       [ 5.44861754],\n",
       "       [ 6.09828995],\n",
       "       [ 5.46773113],\n",
       "       [ 5.19845598],\n",
       "       [ 6.50877151],\n",
       "       [ 5.81376444],\n",
       "       [ 6.35832936],\n",
       "       [ 4.56036289],\n",
       "       [ 5.92421125],\n",
       "       [ 6.59977121],\n",
       "       [ 6.70878382],\n",
       "       [ 5.70609422],\n",
       "       [ 6.84455072],\n",
       "       [ 7.18127191],\n",
       "       [ 5.75958994],\n",
       "       [ 4.95719184],\n",
       "       [ 5.78306739],\n",
       "       [ 5.59579208],\n",
       "       [ 5.72324973],\n",
       "       [ 5.64088019],\n",
       "       [ 6.97188233],\n",
       "       [ 6.12727708],\n",
       "       [ 6.79051899],\n",
       "       [ 5.017091  ],\n",
       "       [ 5.34136406],\n",
       "       [ 7.8445129 ],\n",
       "       [ 5.44398467],\n",
       "       [ 6.29052312],\n",
       "       [ 6.05808833],\n",
       "       [ 5.26878465],\n",
       "       [ 4.43820934],\n",
       "       [ 5.83045518],\n",
       "       [ 5.58703828],\n",
       "       [ 7.00271708],\n",
       "       [ 6.84931809],\n",
       "       [ 5.85917286],\n",
       "       [ 5.6076068 ],\n",
       "       [ 5.31924296],\n",
       "       [ 5.67152537],\n",
       "       [ 5.86482056],\n",
       "       [ 6.20706574],\n",
       "       [ 5.88825392],\n",
       "       [ 5.94967183],\n",
       "       [ 5.43985826],\n",
       "       [ 5.94988108],\n",
       "       [ 6.13003037],\n",
       "       [ 6.93738895],\n",
       "       [ 5.48509484],\n",
       "       [ 6.25993261],\n",
       "       [ 5.82614828],\n",
       "       [ 5.90803276],\n",
       "       [ 6.66193738],\n",
       "       [ 5.91470193],\n",
       "       [ 5.60967426],\n",
       "       [ 6.46092173],\n",
       "       [ 6.77372176],\n",
       "       [ 5.1703366 ],\n",
       "       [ 5.74884086],\n",
       "       [ 5.39255554],\n",
       "       [ 6.44695245],\n",
       "       [ 5.91318094],\n",
       "       [ 6.65688468],\n",
       "       [ 6.36146918],\n",
       "       [ 6.15947331],\n",
       "       [ 7.50435495],\n",
       "       [ 6.69213842],\n",
       "       [ 5.58101293],\n",
       "       [ 5.53884446],\n",
       "       [ 6.43793059],\n",
       "       [ 6.83037769],\n",
       "       [ 5.29933618],\n",
       "       [ 5.77424661],\n",
       "       [ 5.34277542],\n",
       "       [ 5.72623411],\n",
       "       [ 6.61113796],\n",
       "       [ 6.17547437],\n",
       "       [ 5.32404654],\n",
       "       [ 6.5846121 ],\n",
       "       [ 4.59396835],\n",
       "       [ 6.07477676],\n",
       "       [ 4.79565575],\n",
       "       [ 5.5152165 ],\n",
       "       [ 5.1919589 ],\n",
       "       [ 6.48414501],\n",
       "       [ 6.84850836],\n",
       "       [ 6.44810443],\n",
       "       [ 6.49203493],\n",
       "       [ 5.37103176],\n",
       "       [ 5.89887324],\n",
       "       [ 6.91461262],\n",
       "       [ 5.39794243],\n",
       "       [ 6.59815727],\n",
       "       [ 6.3878676 ],\n",
       "       [ 5.37436106],\n",
       "       [ 5.6939908 ],\n",
       "       [ 4.85064091],\n",
       "       [ 5.76328893],\n",
       "       [ 6.60799702],\n",
       "       [ 6.2703886 ],\n",
       "       [ 6.89782782],\n",
       "       [ 6.62083728],\n",
       "       [ 5.72538008],\n",
       "       [ 5.09305349],\n",
       "       [ 5.86403852],\n",
       "       [ 5.27170289],\n",
       "       [ 6.15924487],\n",
       "       [ 5.81506823],\n",
       "       [ 5.7222479 ],\n",
       "       [ 7.05193195],\n",
       "       [ 7.51402743],\n",
       "       [ 6.74831508],\n",
       "       [ 5.63404871],\n",
       "       [ 5.34766995],\n",
       "       [ 5.79416833],\n",
       "       [ 6.45326181],\n",
       "       [ 7.02996292],\n",
       "       [ 6.70295695],\n",
       "       [ 6.00164411],\n",
       "       [ 5.60622865],\n",
       "       [ 7.12067995],\n",
       "       [ 4.99564285],\n",
       "       [ 6.4806127 ],\n",
       "       [ 6.48482195],\n",
       "       [ 6.13823357],\n",
       "       [ 6.61888956],\n",
       "       [ 5.25160807],\n",
       "       [ 6.80610284],\n",
       "       [ 6.81775901],\n",
       "       [ 5.12950606],\n",
       "       [ 4.98270211],\n",
       "       [ 6.12308418],\n",
       "       [ 5.35663127],\n",
       "       [ 6.6822343 ],\n",
       "       [ 6.18254556],\n",
       "       [ 5.0835517 ],\n",
       "       [ 6.4812465 ],\n",
       "       [ 6.79497337],\n",
       "       [ 5.53410753],\n",
       "       [ 5.91055578],\n",
       "       [ 6.42732282],\n",
       "       [ 5.66935235],\n",
       "       [ 7.21194396],\n",
       "       [ 5.02102353],\n",
       "       [ 6.87822676],\n",
       "       [ 5.77464739],\n",
       "       [ 6.20802702],\n",
       "       [ 5.08774118],\n",
       "       [ 6.49732857],\n",
       "       [ 5.14858606],\n",
       "       [ 5.81541812],\n",
       "       [ 5.75842875],\n",
       "       [ 6.3265815 ],\n",
       "       [ 5.88772571],\n",
       "       [ 5.6010686 ],\n",
       "       [ 7.14445444],\n",
       "       [ 6.23586098],\n",
       "       [ 6.19893103],\n",
       "       [ 6.64544361],\n",
       "       [ 6.08122904],\n",
       "       [ 7.0006108 ],\n",
       "       [ 5.25856047],\n",
       "       [ 5.30672935],\n",
       "       [ 5.47726295],\n",
       "       [ 5.33907476],\n",
       "       [ 4.34105601],\n",
       "       [ 7.69782125],\n",
       "       [ 6.37455067],\n",
       "       [ 6.01828267],\n",
       "       [ 5.66063954],\n",
       "       [ 5.23944218],\n",
       "       [ 6.65743053],\n",
       "       [ 5.97823672],\n",
       "       [ 6.54556   ],\n",
       "       [ 6.06870033],\n",
       "       [ 5.46243824],\n",
       "       [ 6.015198  ],\n",
       "       [ 6.99556345],\n",
       "       [ 6.44429144],\n",
       "       [ 6.67808766],\n",
       "       [ 6.59010579],\n",
       "       [ 6.35462647],\n",
       "       [ 6.91863329],\n",
       "       [ 5.1200873 ],\n",
       "       [ 6.65055645],\n",
       "       [ 5.71275292],\n",
       "       [ 5.25342011],\n",
       "       [ 6.00481437],\n",
       "       [ 5.67295278],\n",
       "       [ 5.46898484],\n",
       "       [ 6.22572941],\n",
       "       [ 6.59557944],\n",
       "       [ 6.86540421],\n",
       "       [ 6.33934207],\n",
       "       [ 6.01914863],\n",
       "       [ 5.87666811],\n",
       "       [ 6.10687544],\n",
       "       [ 5.89534098],\n",
       "       [ 6.23060905],\n",
       "       [ 7.05321046],\n",
       "       [ 5.29826737],\n",
       "       [ 6.8992126 ],\n",
       "       [ 6.95641716],\n",
       "       [ 6.43893077],\n",
       "       [ 6.59712761],\n",
       "       [ 5.71839059],\n",
       "       [ 5.29034282],\n",
       "       [ 5.71152311],\n",
       "       [ 7.08582721],\n",
       "       [ 6.89794007],\n",
       "       [ 5.48182579],\n",
       "       [ 6.43337561],\n",
       "       [ 5.60626407],\n",
       "       [ 4.95220879],\n",
       "       [ 5.95792068],\n",
       "       [ 6.12912228],\n",
       "       [ 6.30361716],\n",
       "       [ 6.58407214],\n",
       "       [ 6.39280943],\n",
       "       [ 5.67268094],\n",
       "       [ 5.04008051],\n",
       "       [ 6.90400476],\n",
       "       [ 6.4715337 ],\n",
       "       [ 4.84970988],\n",
       "       [ 5.69669668],\n",
       "       [ 5.47446536],\n",
       "       [ 5.91869969],\n",
       "       [ 7.14237768],\n",
       "       [ 6.8598964 ],\n",
       "       [ 5.0360537 ],\n",
       "       [ 5.67266023],\n",
       "       [ 5.46410914],\n",
       "       [ 6.64583215],\n",
       "       [ 6.68691398],\n",
       "       [ 6.25155795],\n",
       "       [ 5.70011579],\n",
       "       [ 6.41541522],\n",
       "       [ 5.49529879],\n",
       "       [ 5.20535263],\n",
       "       [ 4.94447375],\n",
       "       [ 5.24380289],\n",
       "       [ 6.75528887],\n",
       "       [ 5.93519   ],\n",
       "       [ 6.64686334],\n",
       "       [ 6.08533376],\n",
       "       [ 6.56636028],\n",
       "       [ 6.10055178],\n",
       "       [ 5.63979398],\n",
       "       [ 5.77980891],\n",
       "       [ 5.65114269],\n",
       "       [ 5.55368949],\n",
       "       [ 7.76039309],\n",
       "       [ 6.07134394],\n",
       "       [ 5.41942954],\n",
       "       [ 5.89537861],\n",
       "       [ 4.61565561],\n",
       "       [ 5.31554115],\n",
       "       [ 5.92698433],\n",
       "       [ 5.77086287],\n",
       "       [ 5.29275908],\n",
       "       [ 4.92823461],\n",
       "       [ 7.13482019],\n",
       "       [ 5.583274  ],\n",
       "       [ 6.49164122],\n",
       "       [ 6.01382903],\n",
       "       [ 6.28646358],\n",
       "       [ 5.00363446],\n",
       "       [ 4.81370644],\n",
       "       [ 5.1075352 ],\n",
       "       [ 4.7456166 ],\n",
       "       [ 6.08093096],\n",
       "       [ 5.93038867],\n",
       "       [ 6.4764228 ],\n",
       "       [ 5.05431854],\n",
       "       [ 6.19428855],\n",
       "       [ 5.80378884],\n",
       "       [ 6.14447731],\n",
       "       [ 5.41157008],\n",
       "       [ 6.45788261],\n",
       "       [ 6.46163247],\n",
       "       [ 7.35106764],\n",
       "       [ 6.14655495],\n",
       "       [ 5.20439143],\n",
       "       [ 6.74856364],\n",
       "       [ 5.62064448],\n",
       "       [ 6.66544596],\n",
       "       [ 6.17982348],\n",
       "       [ 6.79845665],\n",
       "       [ 5.44501888],\n",
       "       [ 6.23812055],\n",
       "       [ 6.04465526],\n",
       "       [ 6.56397984],\n",
       "       [ 5.49906343],\n",
       "       [ 6.8394303 ],\n",
       "       [ 7.63907287],\n",
       "       [ 5.52611912],\n",
       "       [ 6.33481157],\n",
       "       [ 6.78236607],\n",
       "       [ 6.46919682],\n",
       "       [ 4.20436412],\n",
       "       [ 6.55773172],\n",
       "       [ 5.51081955],\n",
       "       [ 6.00231843],\n",
       "       [ 6.60268998],\n",
       "       [ 7.29233307],\n",
       "       [ 5.11011496],\n",
       "       [ 6.96554015],\n",
       "       [ 6.9537568 ],\n",
       "       [ 5.99455356],\n",
       "       [ 5.22637357],\n",
       "       [ 6.47605063],\n",
       "       [ 6.01171169],\n",
       "       [ 5.42678538],\n",
       "       [ 5.90757316],\n",
       "       [ 6.6024028 ],\n",
       "       [ 7.04619618],\n",
       "       [ 4.85140902],\n",
       "       [ 7.00341912],\n",
       "       [ 5.0516722 ],\n",
       "       [ 6.83522873],\n",
       "       [ 7.78091388],\n",
       "       [ 6.35443807],\n",
       "       [ 6.26192909],\n",
       "       [ 6.03135646],\n",
       "       [ 6.08143212],\n",
       "       [ 5.51113708],\n",
       "       [ 5.36390814],\n",
       "       [ 6.23294284],\n",
       "       [ 5.95821959],\n",
       "       [ 6.46172312],\n",
       "       [ 6.38753392],\n",
       "       [ 5.75420025],\n",
       "       [ 6.92624909],\n",
       "       [ 7.09051153],\n",
       "       [ 6.18066808],\n",
       "       [ 5.72186531],\n",
       "       [ 6.13742265],\n",
       "       [ 6.12271128],\n",
       "       [ 6.59859052],\n",
       "       [ 6.25894321],\n",
       "       [ 6.59174527],\n",
       "       [ 6.32538591],\n",
       "       [ 4.7590853 ],\n",
       "       [ 6.41631973],\n",
       "       [ 5.40611026],\n",
       "       [ 7.14111768],\n",
       "       [ 6.43397577],\n",
       "       [ 5.13291926],\n",
       "       [ 6.59781473],\n",
       "       [ 6.04332835],\n",
       "       [ 6.70181477],\n",
       "       [ 6.31318922],\n",
       "       [ 4.91803887],\n",
       "       [ 5.8351311 ],\n",
       "       [ 6.85771937],\n",
       "       [ 6.68017049],\n",
       "       [ 5.76153017],\n",
       "       [ 5.786506  ],\n",
       "       [ 6.24565549],\n",
       "       [ 5.98097248],\n",
       "       [ 6.60606118],\n",
       "       [ 6.55234055],\n",
       "       [ 4.46913535],\n",
       "       [ 6.95781844],\n",
       "       [ 6.8438597 ],\n",
       "       [ 6.28407116],\n",
       "       [ 6.41127954],\n",
       "       [ 5.44478738],\n",
       "       [ 6.29758688],\n",
       "       [ 5.78860445],\n",
       "       [ 4.87198355],\n",
       "       [ 6.57185941],\n",
       "       [ 5.56429747],\n",
       "       [ 6.29382036],\n",
       "       [ 5.51909932],\n",
       "       [ 5.81743807],\n",
       "       [ 5.66974966],\n",
       "       [ 5.93177682],\n",
       "       [ 6.43007868],\n",
       "       [ 5.84776043],\n",
       "       [ 5.90979693],\n",
       "       [ 6.05813586],\n",
       "       [ 4.8642077 ],\n",
       "       [ 6.01487025],\n",
       "       [ 5.98411703],\n",
       "       [ 5.85611751],\n",
       "       [ 5.93418158],\n",
       "       [ 5.51935338],\n",
       "       [ 5.40621425],\n",
       "       [ 6.23883594],\n",
       "       [ 5.37612334],\n",
       "       [ 5.69011805],\n",
       "       [ 4.69714433],\n",
       "       [ 4.72883211],\n",
       "       [ 5.82143057],\n",
       "       [ 6.27665251],\n",
       "       [ 6.57322245],\n",
       "       [ 6.34671929],\n",
       "       [ 6.95688401],\n",
       "       [ 6.4336204 ],\n",
       "       [ 4.95627521],\n",
       "       [ 6.64122348],\n",
       "       [ 6.82512199],\n",
       "       [ 5.74506837],\n",
       "       [ 5.70630345],\n",
       "       [ 4.61477777],\n",
       "       [ 5.54258632],\n",
       "       [ 5.49956396],\n",
       "       [ 6.05954435],\n",
       "       [ 5.5996151 ],\n",
       "       [ 6.32318436],\n",
       "       [ 6.56605891],\n",
       "       [ 6.29037156],\n",
       "       [ 6.97559815],\n",
       "       [ 6.02819888],\n",
       "       [ 5.247269  ],\n",
       "       [ 6.82947273],\n",
       "       [ 6.18334469],\n",
       "       [ 6.88006005],\n",
       "       [ 6.14683659],\n",
       "       [ 5.70749488],\n",
       "       [ 4.93442953],\n",
       "       [ 5.84438543],\n",
       "       [ 4.99052797],\n",
       "       [ 5.48874194],\n",
       "       [ 6.32318568],\n",
       "       [ 6.71973013],\n",
       "       [ 5.57327399],\n",
       "       [ 5.39706266],\n",
       "       [ 4.86230783],\n",
       "       [ 5.21079073],\n",
       "       [ 6.62498131],\n",
       "       [ 5.32760073],\n",
       "       [ 5.65677458],\n",
       "       [ 5.39413776],\n",
       "       [ 5.9638555 ],\n",
       "       [ 4.68968671],\n",
       "       [ 7.37777781],\n",
       "       [ 5.8262883 ],\n",
       "       [ 5.77339458],\n",
       "       [ 6.62015235],\n",
       "       [ 6.65567903],\n",
       "       [ 6.08291434],\n",
       "       [ 5.70029485],\n",
       "       [ 5.23699444],\n",
       "       [ 6.34901305],\n",
       "       [ 5.55389321],\n",
       "       [ 5.42671418],\n",
       "       [ 7.26174555],\n",
       "       [ 6.70233642],\n",
       "       [ 6.35838911],\n",
       "       [ 5.06341348],\n",
       "       [ 7.27751892],\n",
       "       [ 5.65540876],\n",
       "       [ 7.21206781],\n",
       "       [ 6.02535457],\n",
       "       [ 5.93735137],\n",
       "       [ 5.99646718],\n",
       "       [ 5.77908279],\n",
       "       [ 4.66526823],\n",
       "       [ 5.99024638],\n",
       "       [ 6.52512325],\n",
       "       [ 5.83389635],\n",
       "       [ 4.77044903],\n",
       "       [ 5.67108742],\n",
       "       [ 6.12452797],\n",
       "       [ 7.17652313],\n",
       "       [ 5.9589688 ],\n",
       "       [ 6.74001291],\n",
       "       [ 6.41154517],\n",
       "       [ 5.57686492],\n",
       "       [ 6.68221848],\n",
       "       [ 5.06105502],\n",
       "       [ 5.24043348],\n",
       "       [ 4.33183259],\n",
       "       [ 5.94578905],\n",
       "       [ 4.23944582],\n",
       "       [ 5.37027256],\n",
       "       [ 5.6038607 ],\n",
       "       [ 7.15633774],\n",
       "       [ 6.59969474],\n",
       "       [ 6.19518826],\n",
       "       [ 5.62023103],\n",
       "       [ 6.05252314],\n",
       "       [ 5.99658534],\n",
       "       [ 5.3349532 ],\n",
       "       [ 6.63658423],\n",
       "       [ 7.09735716],\n",
       "       [ 7.02504081],\n",
       "       [ 4.27955704],\n",
       "       [ 5.1808456 ],\n",
       "       [ 4.88973069],\n",
       "       [ 6.87092356],\n",
       "       [ 6.96830445],\n",
       "       [ 5.83486049],\n",
       "       [ 6.0113289 ],\n",
       "       [ 4.41770572],\n",
       "       [ 5.34145438],\n",
       "       [ 5.27379772],\n",
       "       [ 5.55240432],\n",
       "       [ 6.58838614],\n",
       "       [ 5.67851057],\n",
       "       [ 4.86850542],\n",
       "       [ 5.64247084],\n",
       "       [ 5.16239833],\n",
       "       [ 4.78728355],\n",
       "       [ 5.9183311 ],\n",
       "       [ 6.54771925],\n",
       "       [ 6.96611106],\n",
       "       [ 5.89032861],\n",
       "       [ 5.46021097],\n",
       "       [ 6.56293565],\n",
       "       [ 5.80656267],\n",
       "       [ 5.48389489],\n",
       "       [ 5.33719499],\n",
       "       [ 7.35161924],\n",
       "       [ 6.54897048],\n",
       "       [ 6.74324234],\n",
       "       [ 6.40227027],\n",
       "       [ 5.28889598],\n",
       "       [ 5.37943147],\n",
       "       [ 7.25860551],\n",
       "       [ 5.97192195],\n",
       "       [ 5.32608422],\n",
       "       [ 5.30545911],\n",
       "       [ 5.32474633],\n",
       "       [ 8.15842227],\n",
       "       [ 5.2070504 ],\n",
       "       [ 6.39958694],\n",
       "       [ 6.34188508],\n",
       "       [ 6.02486078],\n",
       "       [ 6.62248428],\n",
       "       [ 6.1550792 ],\n",
       "       [ 5.64940679],\n",
       "       [ 6.86285951],\n",
       "       [ 6.38920544],\n",
       "       [ 6.8685261 ],\n",
       "       [ 6.54006669],\n",
       "       [ 6.26547589],\n",
       "       [ 5.99036702],\n",
       "       [ 7.22255496],\n",
       "       [ 6.08074471],\n",
       "       [ 4.90928858],\n",
       "       [ 6.15715759],\n",
       "       [ 5.08173928],\n",
       "       [ 4.95119289],\n",
       "       [ 6.82124008],\n",
       "       [ 6.92793714],\n",
       "       [ 6.03974735],\n",
       "       [ 6.40785836],\n",
       "       [ 5.00205564],\n",
       "       [ 6.55982492],\n",
       "       [ 5.80910511],\n",
       "       [ 5.13573623],\n",
       "       [ 6.47594848],\n",
       "       [ 6.72487537],\n",
       "       [ 6.87228035],\n",
       "       [ 7.26713252],\n",
       "       [ 4.84270981],\n",
       "       [ 6.37053811],\n",
       "       [ 5.78195432],\n",
       "       [ 6.45410692],\n",
       "       [ 5.57582696],\n",
       "       [ 6.86102134],\n",
       "       [ 7.46682028],\n",
       "       [ 5.66856667],\n",
       "       [ 5.60573623],\n",
       "       [ 5.66267158],\n",
       "       [ 5.24502566],\n",
       "       [ 5.71469545],\n",
       "       [ 5.09012002],\n",
       "       [ 5.2735684 ],\n",
       "       [ 5.38343174],\n",
       "       [ 5.47650523],\n",
       "       [ 6.4084635 ],\n",
       "       [ 5.88048612],\n",
       "       [ 5.73548555],\n",
       "       [ 6.38855259],\n",
       "       [ 5.94121208],\n",
       "       [ 7.19162741],\n",
       "       [ 5.61018476],\n",
       "       [ 6.53955263],\n",
       "       [ 5.54366368],\n",
       "       [ 5.85806829],\n",
       "       [ 4.98100795],\n",
       "       [ 4.98457502],\n",
       "       [ 6.0746669 ],\n",
       "       [ 7.20313075],\n",
       "       [ 5.28917125],\n",
       "       [ 6.55905874],\n",
       "       [ 7.03022451],\n",
       "       [ 4.58123395],\n",
       "       [ 6.82523947],\n",
       "       [ 6.85912903],\n",
       "       [ 5.78504072],\n",
       "       [ 6.5245026 ],\n",
       "       [ 6.27010474],\n",
       "       [ 6.12184265],\n",
       "       [ 6.24351678],\n",
       "       [ 4.78804785],\n",
       "       [ 5.20462126],\n",
       "       [ 5.30271009],\n",
       "       [ 5.79858967],\n",
       "       [ 6.67906274],\n",
       "       [ 7.45236282],\n",
       "       [ 7.23341611],\n",
       "       [ 5.8616479 ],\n",
       "       [ 6.3927939 ],\n",
       "       [ 5.83632236],\n",
       "       [ 7.33704629],\n",
       "       [ 4.7480082 ],\n",
       "       [ 5.68322163],\n",
       "       [ 5.92839632],\n",
       "       [ 6.90479139],\n",
       "       [ 5.24638709],\n",
       "       [ 5.41239527],\n",
       "       [ 5.03848981],\n",
       "       [ 6.29885878],\n",
       "       [ 6.53472756],\n",
       "       [ 5.93186515],\n",
       "       [ 6.38661589],\n",
       "       [ 5.77956141],\n",
       "       [ 6.36887813],\n",
       "       [ 7.27510053],\n",
       "       [ 6.51959504],\n",
       "       [ 6.29790418],\n",
       "       [ 7.23257024],\n",
       "       [ 5.0015069 ],\n",
       "       [ 6.64175883],\n",
       "       [ 6.08353468],\n",
       "       [ 6.64010977],\n",
       "       [ 6.06547275],\n",
       "       [ 6.65172883],\n",
       "       [ 5.29067837],\n",
       "       [ 6.7687355 ],\n",
       "       [ 6.034585  ],\n",
       "       [ 5.41123338],\n",
       "       [ 5.96972574],\n",
       "       [ 5.81498265],\n",
       "       [ 4.59136379],\n",
       "       [ 5.77774055],\n",
       "       [ 5.65571852],\n",
       "       [ 6.68601125],\n",
       "       [ 5.52331438],\n",
       "       [ 7.04802355],\n",
       "       [ 5.69064993],\n",
       "       [ 5.61663524],\n",
       "       [ 5.81317975],\n",
       "       [ 5.8012213 ],\n",
       "       [ 3.64433961],\n",
       "       [ 6.55741603],\n",
       "       [ 5.71751554],\n",
       "       [ 5.85991627],\n",
       "       [ 6.03387869],\n",
       "       [ 6.15042043],\n",
       "       [ 5.35442318],\n",
       "       [ 6.16204386],\n",
       "       [ 6.79307709],\n",
       "       [ 5.67532147],\n",
       "       [ 6.04784022],\n",
       "       [ 6.01282157],\n",
       "       [ 5.2422581 ],\n",
       "       [ 5.70030189],\n",
       "       [ 5.57627601],\n",
       "       [ 5.33697318],\n",
       "       [ 6.95923733],\n",
       "       [ 6.75745709],\n",
       "       [ 5.04999479],\n",
       "       [ 6.48271048],\n",
       "       [ 6.31022978],\n",
       "       [ 5.93708574],\n",
       "       [ 4.23118993],\n",
       "       [ 6.56045936],\n",
       "       [ 5.92573805],\n",
       "       [ 6.26877274],\n",
       "       [ 6.43384042],\n",
       "       [ 5.50327211],\n",
       "       [ 5.3798342 ],\n",
       "       [ 5.64894738],\n",
       "       [ 6.2860955 ],\n",
       "       [ 6.58941586],\n",
       "       [ 6.47126806],\n",
       "       [ 6.69815546],\n",
       "       [ 6.47063516],\n",
       "       [ 4.80884354],\n",
       "       [ 6.06794352],\n",
       "       [ 5.96289246],\n",
       "       [ 5.5881212 ],\n",
       "       [ 5.9793731 ],\n",
       "       [ 5.73688062],\n",
       "       [ 6.39036161],\n",
       "       [ 5.3595005 ],\n",
       "       [ 4.93672186],\n",
       "       [ 5.65906206],\n",
       "       [ 6.84251805],\n",
       "       [ 6.75896272],\n",
       "       [ 6.24406537],\n",
       "       [ 6.4915244 ],\n",
       "       [ 5.23559497],\n",
       "       [ 5.16784574],\n",
       "       [ 5.72455607],\n",
       "       [ 5.05464415],\n",
       "       [ 5.66030844],\n",
       "       [ 6.65142227],\n",
       "       [ 5.60044307],\n",
       "       [ 5.39819267],\n",
       "       [ 6.57665017],\n",
       "       [ 6.90807952],\n",
       "       [ 6.00509995],\n",
       "       [ 5.78970765],\n",
       "       [ 6.04312954],\n",
       "       [ 7.15847681],\n",
       "       [ 6.56568934],\n",
       "       [ 6.65304151],\n",
       "       [ 5.87647775],\n",
       "       [ 6.44535776],\n",
       "       [ 6.86698732],\n",
       "       [ 6.78434119],\n",
       "       [ 5.74421805],\n",
       "       [ 6.55914593],\n",
       "       [ 5.9176678 ],\n",
       "       [ 6.57749578],\n",
       "       [ 5.99474617],\n",
       "       [ 6.25739087],\n",
       "       [ 6.68013806],\n",
       "       [ 5.70606577],\n",
       "       [ 5.47627192],\n",
       "       [ 6.44488224],\n",
       "       [ 5.48771751],\n",
       "       [ 5.31181994],\n",
       "       [ 6.41558332],\n",
       "       [ 5.57460431],\n",
       "       [ 5.90321002],\n",
       "       [ 5.32297757],\n",
       "       [ 6.22917292],\n",
       "       [ 5.76825182],\n",
       "       [ 5.78710266],\n",
       "       [ 6.26180729],\n",
       "       [ 7.050068  ],\n",
       "       [ 5.89331594],\n",
       "       [ 7.16578481],\n",
       "       [ 4.47995598],\n",
       "       [ 7.26486952],\n",
       "       [ 6.05419241],\n",
       "       [ 7.30500604],\n",
       "       [ 5.35832134],\n",
       "       [ 5.52650482],\n",
       "       [ 5.93610327],\n",
       "       [ 6.27593003],\n",
       "       [ 5.22550499],\n",
       "       [ 5.25053443],\n",
       "       [ 5.77120806],\n",
       "       [ 6.06146929],\n",
       "       [ 6.33902661],\n",
       "       [ 7.16116342],\n",
       "       [ 5.80260947],\n",
       "       [ 6.24995224],\n",
       "       [ 4.69922279],\n",
       "       [ 5.54049555],\n",
       "       [ 7.6511005 ],\n",
       "       [ 4.42864695],\n",
       "       [ 6.48002338],\n",
       "       [ 5.3424554 ],\n",
       "       [ 5.36607414],\n",
       "       [ 5.91243006],\n",
       "       [ 5.94369288],\n",
       "       [ 5.35622033],\n",
       "       [ 4.20802662],\n",
       "       [ 5.68003089],\n",
       "       [ 5.73126971],\n",
       "       [ 6.21162868],\n",
       "       [ 5.47815996],\n",
       "       [ 6.0983693 ],\n",
       "       [ 5.61386276],\n",
       "       [ 6.27085577],\n",
       "       [ 6.2170609 ],\n",
       "       [ 5.44842961],\n",
       "       [ 4.76877979],\n",
       "       [ 5.84528826],\n",
       "       [ 7.29896459],\n",
       "       [ 6.61232297],\n",
       "       [ 5.75933215],\n",
       "       [ 6.86230549],\n",
       "       [ 6.22095892],\n",
       "       [ 5.40327891],\n",
       "       [ 6.61932118],\n",
       "       [ 5.21941725],\n",
       "       [ 5.88827094],\n",
       "       [ 6.76619547],\n",
       "       [ 6.12725342],\n",
       "       [ 7.38908849],\n",
       "       [ 5.84774663],\n",
       "       [ 5.32196409],\n",
       "       [ 6.24745865],\n",
       "       [ 6.40299105],\n",
       "       [ 6.56557945],\n",
       "       [ 5.28135964],\n",
       "       [ 5.04088204],\n",
       "       [ 5.82798029],\n",
       "       [ 6.64079874],\n",
       "       [ 6.40550235],\n",
       "       [ 6.39298924],\n",
       "       [ 5.50060399],\n",
       "       [ 5.43072544],\n",
       "       [ 4.36576963],\n",
       "       [ 6.2551485 ],\n",
       "       [ 5.9258057 ],\n",
       "       [ 6.97990672],\n",
       "       [ 7.23774831],\n",
       "       [ 5.35431404],\n",
       "       [ 5.51099269],\n",
       "       [ 5.99207789],\n",
       "       [ 6.29977597],\n",
       "       [ 6.52172661],\n",
       "       [ 6.26729135],\n",
       "       [ 6.54253281],\n",
       "       [ 7.03467269],\n",
       "       [ 5.63116388],\n",
       "       [ 5.22950747],\n",
       "       [ 6.24734489],\n",
       "       [ 5.71045019],\n",
       "       [ 5.68487247],\n",
       "       [ 5.96625346],\n",
       "       [ 7.30916989],\n",
       "       [ 6.55842693],\n",
       "       [ 6.46885932],\n",
       "       [ 6.08093036],\n",
       "       [ 5.20874376],\n",
       "       [ 7.11119065],\n",
       "       [ 6.42897444],\n",
       "       [ 6.50122156],\n",
       "       [ 5.60609206],\n",
       "       [ 5.96177756],\n",
       "       [ 6.62565607],\n",
       "       [ 5.15399286],\n",
       "       [ 6.6700598 ],\n",
       "       [ 5.88113732],\n",
       "       [ 5.77609653],\n",
       "       [ 6.06037703],\n",
       "       [ 6.33095712],\n",
       "       [ 5.40729835],\n",
       "       [ 6.62034201],\n",
       "       [ 5.0502069 ],\n",
       "       [ 6.07143332],\n",
       "       [ 6.26844495],\n",
       "       [ 5.69429706],\n",
       "       [ 5.96419944],\n",
       "       [ 5.66915291],\n",
       "       [ 6.84285515],\n",
       "       [ 5.28382765],\n",
       "       [ 5.97595298],\n",
       "       [ 6.24561304],\n",
       "       [ 6.3345108 ],\n",
       "       [ 5.94714527],\n",
       "       [ 5.47994556],\n",
       "       [ 5.71664299],\n",
       "       [ 6.00806772],\n",
       "       [ 6.09179713],\n",
       "       [ 6.47666922],\n",
       "       [ 4.51247185],\n",
       "       [ 5.01598592],\n",
       "       [ 6.45617148],\n",
       "       [ 6.52124141],\n",
       "       [ 6.39281889],\n",
       "       [ 5.43479921],\n",
       "       [ 6.93652636],\n",
       "       [ 5.99070918],\n",
       "       [ 6.24028661],\n",
       "       [ 5.79303269],\n",
       "       [ 5.49776506],\n",
       "       [ 6.57147061],\n",
       "       [ 5.37713924],\n",
       "       [ 6.72552779],\n",
       "       [ 6.6326253 ],\n",
       "       [ 6.98887115],\n",
       "       [ 6.51037219],\n",
       "       [ 6.83609298],\n",
       "       [ 6.11864219],\n",
       "       [ 6.27230789],\n",
       "       [ 5.94549593],\n",
       "       [ 6.54627131],\n",
       "       [ 5.55549542],\n",
       "       [ 5.73019148],\n",
       "       [ 5.00950438],\n",
       "       [ 6.29193918],\n",
       "       [ 6.52869744],\n",
       "       [ 5.59129619],\n",
       "       [ 6.59065671],\n",
       "       [ 5.38506416],\n",
       "       [ 7.19323063],\n",
       "       [ 5.51684586],\n",
       "       [ 6.54176755],\n",
       "       [ 6.68831296],\n",
       "       [ 5.46286296],\n",
       "       [ 6.54859265],\n",
       "       [ 6.43582723],\n",
       "       [ 5.28168428],\n",
       "       [ 6.09681335],\n",
       "       [ 6.04161827],\n",
       "       [ 5.60782534],\n",
       "       [ 5.93172369],\n",
       "       [ 4.76678436],\n",
       "       [ 5.04775307],\n",
       "       [ 6.06919035],\n",
       "       [ 6.65134026],\n",
       "       [ 5.52735171],\n",
       "       [ 7.46335012],\n",
       "       [ 6.56111472],\n",
       "       [ 5.78868451],\n",
       "       [ 5.12409315],\n",
       "       [ 6.61619103],\n",
       "       [ 6.49448932],\n",
       "       [ 5.81737181],\n",
       "       [ 6.7990543 ],\n",
       "       [ 6.1725865 ],\n",
       "       [ 6.98780431],\n",
       "       [ 5.63620245],\n",
       "       [ 5.76755243],\n",
       "       [ 6.66699799],\n",
       "       [ 6.27474947],\n",
       "       [ 6.87091962],\n",
       "       [ 5.66487977],\n",
       "       [ 7.2167638 ],\n",
       "       [ 6.14586524],\n",
       "       [ 6.63477734],\n",
       "       [ 6.07874224],\n",
       "       [ 6.6370432 ],\n",
       "       [ 5.59057873],\n",
       "       [ 5.27682741],\n",
       "       [ 6.26850063],\n",
       "       [ 6.22250647],\n",
       "       [ 5.89433989],\n",
       "       [ 7.950873  ],\n",
       "       [ 6.11704514],\n",
       "       [ 6.37509267],\n",
       "       [ 6.22023555],\n",
       "       [ 5.5750029 ],\n",
       "       [ 6.8584195 ],\n",
       "       [ 6.77296481],\n",
       "       [ 5.9906956 ],\n",
       "       [ 4.99822364],\n",
       "       [ 6.48981875],\n",
       "       [ 5.51467827],\n",
       "       [ 5.67893037],\n",
       "       [ 5.79216082],\n",
       "       [ 6.37714671],\n",
       "       [ 6.14555038]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "            covars_weight=1, init_params='cm', means_prior=0, means_weight=0,\n",
       "            min_covar=0.001, n_components=4, n_iter=10, params='mtc',\n",
       "            random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "            transmat_prior=1.0, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\",init_params=\"cm\", params=\"mtc\")\n",
    "lr.startprob_ = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "lr.transmat_ = np.array([[0.5, 0.5, 0.0, 0.0],[0.0, 0.5, 0.5, 0.0],[0.0, 0.0, 0.5, 0.5],[0.0,0.0,0.0,1.0]])\n",
    "lr.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.66666664, 0.33333336],\n",
       "       [0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1         2         3\n",
       "0  0.0  1.0  0.000000  0.000000\n",
       "1  0.0  0.0  1.000000  0.000000\n",
       "2  0.0  0.0  0.666667  0.333333\n",
       "3  0.0  0.0  0.000000  1.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lr.transmat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.78741127],\n",
       "        [-0.85468068],\n",
       "        [ 2.2804706 ],\n",
       "        [ 6.01303355]]), array([[[0.01      ]],\n",
       " \n",
       "        [[0.01      ]],\n",
       " \n",
       "        [[0.07577723]],\n",
       " \n",
       "        [[0.45954586]]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.means_, lr.covars_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
