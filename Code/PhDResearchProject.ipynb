{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import norm\n",
    "import pomegranate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data and diving them into unique unit numbers\n",
    "\n",
    "We need to divide data into unique numbers, because the state restes as the unit number changes, so we need to find Gaussian distribution for different unit numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Documents/hitachi/CMAPSS/train_FD001.txt', sep=\" \", header=None)\n",
    "unique_unit_values = data[0].unique() #Number of units\n",
    "data_cycles = []\n",
    "for unit_num in unique_unit_values:\n",
    "    data_cycles.append(data[data[0] == unit_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing operational settings and normalize the data column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    x = data.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    dataNew = pd.DataFrame(x_scaled)\n",
    "    return dataNew\n",
    "#Remove the operation settings\n",
    "dataT = data[data.columns[5:26]]\n",
    "dataT.columns = range(21)\n",
    "dataT = normalize(dataT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing data for each unit\n",
    "\n",
    "I think this is why my transitional matrix previously was not working properly as in each unit the state resets and start from good condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT_cycles = []\n",
    "for unit_num in unique_unit_values:\n",
    "    dataT_cycles.append(dataT[data[0] == unit_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying and removing non variable data columns\n",
    "\n",
    "Removing the columns where the data does not vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 5, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n",
      "Int64Index([0, 4, 9, 15, 17, 18], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "for dataT_cycle in dataT_cycles:\n",
    "    print(dataT_cycle.columns[dataT_cycle.std() == 0])\n",
    "\"\"\"\n",
    "Here we can see 0,4,9,15,17,18 but also 5 at many places so we drop column number 5 as well\n",
    "\"\"\"\n",
    "dataT.drop(data.columns[[0, 3, 4, 5, 9, 15, 17, 18]],axis=1,inplace=True)\n",
    "dataT.columns = range(13)\n",
    "dataT_cycles = []\n",
    "for unit_num in unique_unit_values:\n",
    "    dataT_cycles.append(dataT[data[0] == unit_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Right now only using the first data frame (i.e Machine 1) to train the VAE, but we can combine all the dataframes\n",
    "# and train the VAE jointly on the entire data for better performance \n",
    "\n",
    "x_train = dataT_cycles[0].values[:150]\n",
    "x_test = dataT_cycles[0].values[151:198]\n",
    "x_train.shape\n",
    "# x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoders to find Latent State Space Distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e2e8ac5a5bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "x_train = dataT_cycles[0].values[:100]\n",
    "x_test = dataT_cycles[0].values[101:198]\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "original_dim = x_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (original_dim, )\n",
    "intermediate_dim = 9\n",
    "batch_size = 10\n",
    "latent_dim = 5\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "# z = z_mean + sqrt(var)*eps\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    \n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9)            126         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 5)            50          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 5)            50          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 5)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 226\n",
      "Trainable params: 226\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VAE Model Encoder + Decoder \n",
    "\n",
    "# Building the Encoder\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                130       \n",
      "=================================================================\n",
      "Total params: 184\n",
      "Trainable params: 184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build decoder model \n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    help_ = \"Load h5 model trained weights\"\n",
    "    parser.add_argument(\"-w\", \"--weights\", help=help_)\n",
    "    help_ = \"Use mse loss instead of binary cross entropy (default)\"\n",
    "    parser.add_argument(\"-m\", \"--mse\", help=help_, action='store_true')\n",
    "    \n",
    "    models = (encoder, decoder)\n",
    "    data = (x_test, None)\n",
    "    \n",
    "    # VAE loss = mse_loss or xent_loss + kl_loss\n",
    "    if args.mse:\n",
    "        reconstruction_loss = mse(inputs, outputs)\n",
    "    else:\n",
    "        reconstruction_loss = binary_crossentropy(inputs, outputs)\n",
    "        \n",
    "    reconstruction_loss *= original_dim\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis= -1)\n",
    "    kl_loss *= 0.5 \n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "    vae.summary()\n",
    "    \n",
    "    if args.weights:\n",
    "        vae.load_weights(args.weights)\n",
    "    else:\n",
    "        # Train the autoencoder\n",
    "        vae.fit(x_train, epochs=epochs, batch_size= batch_size, validation_data=(x_test, None))\n",
    "        vae.save_weights('vae_mlp_CMAPSS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yannik/miniconda3/envs/ykp/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"vae_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 5), (None, 5), (N 226       \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 13)                184       \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yannik/miniconda3/envs/ykp/lib/python3.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yannik/miniconda3/envs/ykp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 100 samples, validate on 91 samples\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 8.6136 - val_loss: 7.5069\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 159us/step - loss: 8.1071 - val_loss: 6.7097\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 176us/step - loss: 7.4209 - val_loss: 5.7314\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 188us/step - loss: 6.5338 - val_loss: 4.2211\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 188us/step - loss: 5.2482 - val_loss: 2.3457\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 222us/step - loss: 3.4696 - val_loss: -0.6214\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 234us/step - loss: 0.8200 - val_loss: -4.6524\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 233us/step - loss: -3.1063 - val_loss: -10.8377\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 199us/step - loss: -8.8391 - val_loss: -20.2851\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 221us/step - loss: -17.8439 - val_loss: -35.3720\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 212us/step - loss: -32.3196 - val_loss: -61.8668\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 189us/step - loss: -57.6569 - val_loss: -110.5614\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 192us/step - loss: -103.0687 - val_loss: -209.2532\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 172us/step - loss: -193.8839 - val_loss: -428.7604\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 166us/step - loss: -395.5606 - val_loss: -973.5886\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 171us/step - loss: -876.5469 - val_loss: -2465.3963\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 164us/step - loss: -2140.9943 - val_loss: -6978.1396\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 191us/step - loss: -5912.4380 - val_loss: -21969.4612\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 168us/step - loss: -17524.6221 - val_loss: -76693.2080\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 192us/step - loss: -58330.1199 - val_loss: -299755.0117\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 175us/step - loss: -211254.3961 - val_loss: -1294789.7390\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 170us/step - loss: -824078.1781 - val_loss: -6254041.3846\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 189us/step - loss: -3874470.8000 - val_loss: -33839958.4615\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 179us/step - loss: -17673889.2000 - val_loss: -203298941.5385\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 187us/step - loss: -93301684.8000 - val_loss: -1389514401.7582\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 174us/step - loss: -575689105.6000 - val_loss: -10388783064.6154\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 190us/step - loss: -3859205760.0000 - val_loss: -91073077878.1538\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 195us/step - loss: -27723500134.4000 - val_loss: -887367626166.8572\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 191us/step - loss: -211455042355.2000 - val_loss: -9740658291363.1641\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 226us/step - loss: -1892797120512.0000 - val_loss: -123805296555919.4688\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 212us/step - loss: -17698189370982.3984 - val_loss: -1668533313927055.5000\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 233us/step - loss: -171281844115865.5938 - val_loss: -24902474047814240.0000\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 221us/step - loss: -2271257136254157.0000 - val_loss: -430710419582321728.0000\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 214us/step - loss: -30693065758448024.0000 - val_loss: -8158398050467080192.0000\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 194us/step - loss: -391592129236828160.0000 - val_loss: -168394750595001450496.0000\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 225us/step - loss: nan - val_loss: nan\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 176us/step - loss: nan - val_loss: nan\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 190us/step - loss: nan - val_loss: nan\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 177us/step - loss: nan - val_loss: nan\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 184us/step - loss: nan - val_loss: nan\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 185us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 187us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 188us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 177us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 163us/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    mse = None\n",
    "    weights = None\n",
    "    \n",
    "args = Args()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the VAE has been trained, we can use the encoder to sample the latent space\n",
    "\n",
    "#predicting the latent space for first 13 observation values for machine 1\n",
    "test = np.asarray(x_train[0:13])  \n",
    "\n",
    "# indexing on 2 because the encoder predicts z_mean, z_log_var and sampled vector z (we are interested in z only)\n",
    "latent_space = encoder.predict(test)[2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each list is a 5 dimension latent state space for that observation value\n",
    "latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the raw observation from the learned latent space \n",
    "sample = decoder.predict(latent_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18373494, 0.40680183, 0.72624799, 0.24242424, 0.109755  ,\n",
       "       0.36904762, 0.63326226, 0.20588235, 0.1996078 , 0.36398615,\n",
       "       0.33333333, 0.71317829, 0.7246617 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the with the real x_train value\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Right now they are not same as we trained the VAE on very less amount of data \n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using HMM to find out transitional matrices\n",
    "\n",
    "Here we first define transmatrix as [[0.5, 0.5, 0.0, 0.0],[0.0, 0.4, 0.6, 0.0],[0.0, 0.0, 0.3, 0.7],[0.0,0.0,0.0,1.0]] which means there is half chance for each state to go to next state and half to remain in the current state itself when fully healthy, 0.4 probability of remaining at current state when at 'above average' health, 0.3 probability when 'below average', and with certainty to stay at a failing state if already failing.\n",
    "\n",
    "Then we train for each unit for transmatrix as well as state means and we will take average of each unit transmatrices and states as the transmatrix and state\n",
    "\n",
    "*Note*: Here state '0' means the perfect health and '3' means weakest health "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.726248</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.109755</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.633262</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.628019</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.140043</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.149960</td>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.683235</td>\n",
       "      <td>0.336554</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.072602</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.234542</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.091599</td>\n",
       "      <td>0.753367</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.286822</td>\n",
       "      <td>0.089202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.894578</td>\n",
       "      <td>0.547853</td>\n",
       "      <td>0.136876</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.102396</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.189765</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.090670</td>\n",
       "      <td>0.744132</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.301712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.731928</td>\n",
       "      <td>0.614345</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.084582</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.287846</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.065229</td>\n",
       "      <td>0.759523</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>0.239299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.641566</td>\n",
       "      <td>0.682799</td>\n",
       "      <td>0.172303</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.094364</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.187633</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.075704</td>\n",
       "      <td>0.740669</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.240310</td>\n",
       "      <td>0.324910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.701807</td>\n",
       "      <td>0.662089</td>\n",
       "      <td>0.225443</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.051557</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.296375</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.056714</td>\n",
       "      <td>0.717199</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.097625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.183735  0.406802  0.726248  0.242424  0.109755  0.369048  0.633262   \n",
       "1    0.283133  0.453019  0.628019  0.212121  0.100242  0.380952  0.765458   \n",
       "2    0.343373  0.369523  0.710145  0.272727  0.140043  0.250000  0.795309   \n",
       "3    0.343373  0.256159  0.740741  0.318182  0.124518  0.166667  0.889126   \n",
       "4    0.349398  0.257467  0.668277  0.242424  0.149960  0.255952  0.746269   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "187  0.765060  0.683235  0.336554  0.621212  0.072602  0.684524  0.234542   \n",
       "188  0.894578  0.547853  0.136876  0.560606  0.102396  0.732143  0.189765   \n",
       "189  0.731928  0.614345  0.231884  0.590909  0.084582  0.880952  0.287846   \n",
       "190  0.641566  0.682799  0.172303  0.575758  0.094364  0.773810  0.187633   \n",
       "191  0.701807  0.662089  0.225443  0.636364  0.051557  0.833333  0.296375   \n",
       "\n",
       "            7         8         9        10        11        12  \n",
       "0    0.205882  0.199608  0.363986  0.333333  0.713178  0.724662  \n",
       "1    0.279412  0.162813  0.411312  0.333333  0.666667  0.731014  \n",
       "2    0.220588  0.171793  0.357445  0.166667  0.627907  0.621375  \n",
       "3    0.294118  0.174889  0.166603  0.333333  0.573643  0.662386  \n",
       "4    0.235294  0.174734  0.402078  0.416667  0.589147  0.704502  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "187  0.514706  0.091599  0.753367  0.666667  0.286822  0.089202  \n",
       "188  0.661765  0.090670  0.744132  0.583333  0.263566  0.301712  \n",
       "189  0.691176  0.065229  0.759523  0.833333  0.271318  0.239299  \n",
       "190  0.617647  0.075704  0.740669  0.500000  0.240310  0.324910  \n",
       "191  0.647059  0.056714  0.717199  0.666667  0.263566  0.097625  \n",
       "\n",
       "[192 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataT_cycles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\",init_params=\"cm\", params=\"mtc\")\n",
    "lr.startprob_ = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "transmats = []\n",
    "statemeans = []\n",
    "covars = []\n",
    "for i in range(100):\n",
    "    lr.transmat_ = np.array([[0.5, 0.5, 0.0, 0.0],[0.0, 0.4, 0.6, 0.0],[0.0, 0.0, 0.3, 0.7],[0.0,0.0,0.0,1.0]])\n",
    "    lr.fit(dataT_cycles[i])\n",
    "    transmats.append(lr.transmat_)\n",
    "    statemeans.append(lr.means_)\n",
    "    covars.append(lr.covars_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = hmm.GMMHMM(n_components=4, n_mix=4, covariance_type=\"diag\",init_params=\"cm\", params=\"mt\")\n",
    "#lr.startprob_ = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "#transmats = []\n",
    "#statemeans = []\n",
    "#for i in range(100):\n",
    "#    lr.transmat_ = np.array([[0.5, 0.5, 0.0, 0.0],[0.0, 0.5, 0.5, 0.0],[0.0, 0.0, 0.5, 0.5],[0.0,0.0,0.0,1.0]])\n",
    "#    lr.fit(dataT_cycles[i])\n",
    "#    transmat = lr.transmat_\n",
    "#    transmats.append(transmat)\n",
    "#    statemeans.append(lr.means_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transmat = np.array(transmats).mean(axis=0)\n",
    "statemean = np.array(statemeans).mean(axis=0)\n",
    "covar = np.array(covars).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63481339, 0.36518661, 0.        , 0.        ],\n",
       "       [0.        , 0.75998224, 0.24001776, 0.        ],\n",
       "       [0.        , 0.        , 0.86364041, 0.13635959],\n",
       "       [0.        , 0.        , 0.        , 0.97      ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.634813</td>\n",
       "      <td>0.365187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.240018</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863640</td>\n",
       "      <td>0.13636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2        3\n",
       "0  0.634813  0.365187  0.000000  0.00000\n",
       "1  0.000000  0.759982  0.240018  0.00000\n",
       "2  0.000000  0.000000  0.863640  0.13636\n",
       "3  0.000000  0.000000  0.000000  0.97000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.373991</td>\n",
       "      <td>0.355053</td>\n",
       "      <td>0.638671</td>\n",
       "      <td>0.250417</td>\n",
       "      <td>0.159337</td>\n",
       "      <td>0.318412</td>\n",
       "      <td>0.665821</td>\n",
       "      <td>0.273018</td>\n",
       "      <td>0.199115</td>\n",
       "      <td>0.374948</td>\n",
       "      <td>0.364711</td>\n",
       "      <td>0.596296</td>\n",
       "      <td>0.622337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.460442</td>\n",
       "      <td>0.442518</td>\n",
       "      <td>0.542787</td>\n",
       "      <td>0.308376</td>\n",
       "      <td>0.196155</td>\n",
       "      <td>0.431706</td>\n",
       "      <td>0.557742</td>\n",
       "      <td>0.330440</td>\n",
       "      <td>0.223821</td>\n",
       "      <td>0.474325</td>\n",
       "      <td>0.450489</td>\n",
       "      <td>0.500078</td>\n",
       "      <td>0.529516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.579848</td>\n",
       "      <td>0.545131</td>\n",
       "      <td>0.423885</td>\n",
       "      <td>0.394580</td>\n",
       "      <td>0.257473</td>\n",
       "      <td>0.584895</td>\n",
       "      <td>0.412929</td>\n",
       "      <td>0.410217</td>\n",
       "      <td>0.273188</td>\n",
       "      <td>0.598722</td>\n",
       "      <td>0.559461</td>\n",
       "      <td>0.388988</td>\n",
       "      <td>0.404967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.707840</td>\n",
       "      <td>0.649656</td>\n",
       "      <td>0.302126</td>\n",
       "      <td>0.480435</td>\n",
       "      <td>0.322745</td>\n",
       "      <td>0.728482</td>\n",
       "      <td>0.269718</td>\n",
       "      <td>0.499237</td>\n",
       "      <td>0.328579</td>\n",
       "      <td>0.718459</td>\n",
       "      <td>0.670446</td>\n",
       "      <td>0.266945</td>\n",
       "      <td>0.274311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.373991  0.355053  0.638671  0.250417  0.159337  0.318412  0.665821   \n",
       "1  0.460442  0.442518  0.542787  0.308376  0.196155  0.431706  0.557742   \n",
       "2  0.579848  0.545131  0.423885  0.394580  0.257473  0.584895  0.412929   \n",
       "3  0.707840  0.649656  0.302126  0.480435  0.322745  0.728482  0.269718   \n",
       "\n",
       "          7         8         9        10        11        12  \n",
       "0  0.273018  0.199115  0.374948  0.364711  0.596296  0.622337  \n",
       "1  0.330440  0.223821  0.474325  0.450489  0.500078  0.529516  \n",
       "2  0.410217  0.273188  0.598722  0.559461  0.388988  0.404967  \n",
       "3  0.499237  0.328579  0.718459  0.670446  0.266945  0.274311  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(statemean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_prob = np.array([transmat, transmat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array([[100, 50, 0, -50],[-50, 0, 50, 100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-50</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2    3\n",
       "0  100  50   0  -50\n",
       "1  -50   0  50  100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9.31506823e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 8.86169403e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 6.89448238e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.25110531e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         4.02229235e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 6.74538921e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 6.93002407e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.19656647e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         3.95696710e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 7.99366317e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 7.98425060e-03, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.06436711e-03,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         8.60416624e-03]],\n",
       "\n",
       "       [[1.04104987e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 9.19411937e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 7.42036549e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.76732805e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         3.65594506e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 7.50265346e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 7.71002973e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.75717576e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         3.48953133e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 8.34252879e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 8.28900332e-03, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.10472413e-03,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         9.27372458e-03]],\n",
       "\n",
       "       [[1.50009345e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 1.50008571e+02, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.50006351e+02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.50003774e+02,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         1.50002989e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.50007243e+02, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.50007201e+02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.50003679e+02,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         1.50002786e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.50007720e+02, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.50007567e+02, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.50007866e+02,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         1.50008313e+02]],\n",
       "\n",
       "       [[5.50005307e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 5.50004339e+02, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 5.50003528e+02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.50002362e+02,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         5.50001631e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 5.50004214e+02, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 5.50004011e+02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.50002330e+02,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         5.50001483e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 5.50004401e+02, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 5.50004158e+02, 0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.50004673e+02,\n",
       "         0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         5.50004841e+02]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar=[covar[i].sum(axis=1) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.006894</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>0.007994</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.008604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.008343</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>0.009274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>150.009345</td>\n",
       "      <td>150.008571</td>\n",
       "      <td>150.006351</td>\n",
       "      <td>150.003774</td>\n",
       "      <td>150.002989</td>\n",
       "      <td>150.007243</td>\n",
       "      <td>150.007201</td>\n",
       "      <td>150.003679</td>\n",
       "      <td>150.002786</td>\n",
       "      <td>150.007720</td>\n",
       "      <td>150.007567</td>\n",
       "      <td>150.007866</td>\n",
       "      <td>150.008313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>550.005307</td>\n",
       "      <td>550.004339</td>\n",
       "      <td>550.003528</td>\n",
       "      <td>550.002362</td>\n",
       "      <td>550.001631</td>\n",
       "      <td>550.004214</td>\n",
       "      <td>550.004011</td>\n",
       "      <td>550.002330</td>\n",
       "      <td>550.001483</td>\n",
       "      <td>550.004401</td>\n",
       "      <td>550.004158</td>\n",
       "      <td>550.004673</td>\n",
       "      <td>550.004841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5  \\\n",
       "0    0.009315    0.008862    0.006894    0.005251    0.004022    0.006745   \n",
       "1    0.010410    0.009194    0.007420    0.004767    0.003656    0.007503   \n",
       "2  150.009345  150.008571  150.006351  150.003774  150.002989  150.007243   \n",
       "3  550.005307  550.004339  550.003528  550.002362  550.001631  550.004214   \n",
       "\n",
       "            6           7           8           9          10          11  \\\n",
       "0    0.006930    0.005197    0.003957    0.007994    0.007984    0.008064   \n",
       "1    0.007710    0.004757    0.003490    0.008343    0.008289    0.008105   \n",
       "2  150.007201  150.003679  150.002786  150.007720  150.007567  150.007866   \n",
       "3  550.004011  550.002330  550.001483  550.004401  550.004158  550.004673   \n",
       "\n",
       "           12  \n",
       "0    0.008604  \n",
       "1    0.009274  \n",
       "2  150.008313  \n",
       "3  550.004841  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prob = np.array([norm.pdf(statemean,covar), norm.pdf(statemean,covar)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.37327764, 0.37573823, 0.3267665 , 0.38713115, 0.39415941,\n",
       "         0.38002938, 0.32109851, 0.38488808, 0.391417  , 0.37296664,\n",
       "         0.37434949, 0.33556263, 0.33045909],\n",
       "        [0.3605219 , 0.36319214, 0.34567815, 0.38097265, 0.39161874,\n",
       "         0.36461511, 0.34293784, 0.37833576, 0.38937535, 0.35789756,\n",
       "         0.36178362, 0.35346976, 0.34844858],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.37327764, 0.37573823, 0.3267665 , 0.38713115, 0.39415941,\n",
       "         0.38002938, 0.32109851, 0.38488808, 0.391417  , 0.37296664,\n",
       "         0.37434949, 0.33556263, 0.33045909],\n",
       "        [0.3605219 , 0.36319214, 0.34567815, 0.38097265, 0.39161874,\n",
       "         0.36461511, 0.34293784, 0.37833576, 0.38937535, 0.35789756,\n",
       "         0.36178362, 0.35346976, 0.34844858],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: no-repair, 1: repair\n",
    "actions = ('0', '1')\n",
    "# 0: failing, 1: low health, 2: good health, 3: perfect health\n",
    "states = ('0', '1', '2', '3')\n",
    "\n",
    "discount = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First we define an MDP. We also represent a policy\n",
    "as a dictionary of {state: action} pairs, and a utility function as a\n",
    "dictionary of {state: number} pairs. We then define the value_iteration\n",
    "and policy_iteration algorithms.\"\"\"\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class MDP:\n",
    "\n",
    "    \"\"\"A Markov Decision Process, defined by an initial state, transition model,\n",
    "    and reward function. We also keep track of a gamma value, for use by\n",
    "    algorithms. The transition model is represented somewhat differently from\n",
    "    the text. Instead of P(s' | s, a) being a probability number for each\n",
    "    state/state/action triplet, we instead have T(s, a) return a\n",
    "    list of (p, s') pairs. We also keep track of the possible states,\n",
    "    terminal states, and actions for each state.\"\"\"\n",
    "\n",
    "    def __init__(self, init, actlist, terminals, transitions=None, reward=None, states=None, discount=0.9):\n",
    "        if not (0 < discount <= 1):\n",
    "            raise ValueError(\"An MDP must have 0 < discount <= 1\")\n",
    "\n",
    "        # collect states from transitions table if not passed.\n",
    "        self.states = states or self.get_states_from_transitions(transitions)\n",
    "            \n",
    "        self.init = init\n",
    "        \n",
    "        if isinstance(actlist, list):\n",
    "            # if actlist is a list, all states have the same actions\n",
    "            self.actlist = actlist\n",
    "\n",
    "        elif isinstance(actlist, dict):\n",
    "            # if actlist is a dict, different actions for each state\n",
    "            self.actlist = actlist\n",
    "        \n",
    "        self.terminals = terminals\n",
    "        self.transitions = transitions or {}\n",
    "        if not self.transitions:\n",
    "            print(\"Warning: Transition table is empty.\")\n",
    "            \n",
    "        self.discount = discount\n",
    "        \n",
    "        # maybe I should change this\n",
    "        # self.gamma = gamma\n",
    "\n",
    "        self.reward = reward or {s: 0 for s in self.states}\n",
    "\n",
    "        # self.check_consistency()\n",
    "\n",
    "    def R(self, state):\n",
    "        \"\"\"Return a numeric reward for this state.\"\"\"\n",
    "\n",
    "        return self.reward[state]\n",
    "\n",
    "    def T(self, state, action):\n",
    "        \"\"\"Transition model. From a state and an action, return a list\n",
    "        of (probability, result-state) pairs.\"\"\"\n",
    "\n",
    "        if not self.transitions:\n",
    "            raise ValueError(\"Transition model is missing\")\n",
    "        else:\n",
    "            return self.transitions[state][action]\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"Return a list of actions that can be performed in this state. By default, a\n",
    "        fixed list of actions, except for terminal states. Override this\n",
    "        method if you need to specialize by state.\"\"\"\n",
    "\n",
    "        if state in self.terminals:\n",
    "            return [None]\n",
    "        else:\n",
    "            return self.actlist\n",
    "\n",
    "    def get_states_from_transitions(self, transitions):\n",
    "        if isinstance(transitions, dict):\n",
    "            s1 = set(transitions.keys())\n",
    "            s2 = set(tr[1] for actions in transitions.values()\n",
    "                     for effects in actions.values()\n",
    "                     for tr in effects)\n",
    "            return s1.union(s2)\n",
    "        else:\n",
    "            print('Could not retrieve states from transitions')\n",
    "            return None\n",
    "\n",
    "    def check_consistency(self):\n",
    "\n",
    "        # check that all states in transitions are valid\n",
    "        assert set(self.states) == self.get_states_from_transitions(self.transitions)\n",
    "\n",
    "        # check that init is a valid state\n",
    "        assert self.init in self.states\n",
    "\n",
    "        # check reward for each state\n",
    "        assert set(self.reward.keys()) == set(self.states)\n",
    "\n",
    "        # check that all terminals are valid states\n",
    "        assert all(t in self.states for t in self.terminals)\n",
    "\n",
    "        # check that probability distributions for all actions sum to 1\n",
    "        for s1, actions in self.transitions.items():\n",
    "            for a in actions.keys():\n",
    "                s = 0\n",
    "                for o in actions[a]:\n",
    "                    s += o[0]\n",
    "                assert abs(s - 1) < 0.001\n",
    "\n",
    "class POMDP(MDP):\n",
    "\n",
    "    \"\"\"A Partially Observable Markov Decision Process, defined by\n",
    "    a transition model P(s'|s,a), actions A(s), a reward function R(s),\n",
    "    and a sensor model P(e|s). We also keep track of a gamma value,\n",
    "    for use by algorithms. The transition and the sensor models\n",
    "    are defined as matrices. We also keep track of the possible states\n",
    "    and actions for each state.\"\"\"\n",
    "\n",
    "    def __init__(self, actions, transitions=None, evidences=None, rewards=None, states=None, discount=0.95):\n",
    "        \"\"\"Initialize variables of the pomdp\"\"\"\n",
    "\n",
    "        if not (0 < discount <= 1):\n",
    "            raise ValueError('A POMDP must have 0 < discount <= 1')\n",
    "\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "\n",
    "        # transition model cannot be undefined\n",
    "        self.t_prob = transitions\n",
    "        if not self.t_prob.any():\n",
    "            print('Warning: Transition model is undefined')\n",
    "        \n",
    "        # sensor model cannot be undefined\n",
    "        self.e_prob = evidences\n",
    "        if not self.e_prob.any():\n",
    "            print('Warning: Sensor model is undefined')\n",
    "        \n",
    "        self.discount = discount\n",
    "        # may have to change this\n",
    "        # self.gamma = gamma\n",
    "        self.rewards = rewards\n",
    "        \n",
    "class Matrix:\n",
    "    \"\"\"Matrix operations class\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def add(A, B):\n",
    "        \"\"\"Add two matrices A and B\"\"\"\n",
    "\n",
    "        res = []\n",
    "        for i in range(len(A)):\n",
    "            row = []\n",
    "            for j in range(len(A[0])):\n",
    "                row.append(A[i][j] + B[i][j])\n",
    "            res.append(row)\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def scalar_multiply(a, B):\n",
    "        \"\"\"Multiply scalar a to matrix B\"\"\"\n",
    "\n",
    "        for i in range(len(B)):\n",
    "            for j in range(len(B[0])):\n",
    "                B[i][j] = a * B[i][j]\n",
    "        return B\n",
    "\n",
    "    @staticmethod\n",
    "    def multiply(A, B):\n",
    "        \"\"\"Multiply two matrices A and B element-wise\"\"\"\n",
    "\n",
    "        matrix = []\n",
    "        for i in range(len(B)):\n",
    "            row = []\n",
    "            for j in range(len(B[0])):\n",
    "                row.append(B[i][j] * A[j][i])\n",
    "            matrix.append(row)\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def matmul(A, B):\n",
    "        \"\"\"Inner-product of two matrices\"\"\"\n",
    "\n",
    "        return [[sum(ele_a*ele_b for ele_a, ele_b in zip(row_a, col_b)) for col_b in list(zip(*B))] for row_a in A]\n",
    "\n",
    "    @staticmethod\n",
    "    def transpose(A):\n",
    "        \"\"\"Transpose a matrix\"\"\"\n",
    "        \n",
    "        return [list(i) for i in zip(*A)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving POMDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaVector:\n",
    "    \"\"\"\n",
    "    Simple wrapper for an alpha vector, used for representing the value function for a POMDP as a piecewise-linear,\n",
    "    convex function\n",
    "    \"\"\"\n",
    "    def __init__(self, a, v):\n",
    "        self.action = a\n",
    "        self.v = v\n",
    "\n",
    "    def copy(self):\n",
    "        return AlphaVector(self.action, self.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration:\n",
    "    def __init__(self, pomdp):\n",
    "        \"\"\"\n",
    "        Initialize the POMDP exact value iteration solver\n",
    "        :param agent:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.model = pomdp\n",
    "        self.gamma = set()\n",
    "\n",
    "    def value_iteration(self, horizon):\n",
    "        \"\"\"\n",
    "        Solve the POMDP by computing all alpha vectors\n",
    "        :param t: transition probability matrix\n",
    "        :param o: observation probability matrix\n",
    "        :param r: immediate rewards matrix\n",
    "        :param horizon: integer valued scalar represented the number of planning steps\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        t = self.model.t_prob\n",
    "        o = self.model.e_prob\n",
    "        r = self.model.reward\n",
    "        # the above three are used later--important\n",
    "        discount = self.model.discount\n",
    "        actions = len(self.model.actions)  # |A| actions\n",
    "        states = len(self.model.states)  # |S| states\n",
    "        # I might need to change this\n",
    "        observations = len(self.model.get_all_observations())  # |Z| observations\n",
    "        first = True\n",
    "\n",
    "        # initialize gamma with a 0 alpha-vector\n",
    "        dummy = AlphaVector(a=-1, v=np.zeros(states))\n",
    "        self.gamma.add(dummy)\n",
    "\n",
    "        # start with 1 step planning horizon, up to horizon-length planning horizon\n",
    "        for k in range(horizon):\n",
    "            print('[Value Iteration] planning horizon {}...'.format(k))\n",
    "            # new set of alpha vectors to add to set gamma\n",
    "            gamma_k = set()\n",
    "            # Compute the new coefficients for the new alpha-vectors\n",
    "            v_new = np.zeros(shape=(len(self.gamma), actions, observations, states))\n",
    "            idx = 0\n",
    "            for v in self.gamma:\n",
    "                for u in range(actions):\n",
    "                    for z in range(observations):\n",
    "                        for j in range(states):\n",
    "                            for i in range(states):\n",
    "                                # v_i_k * p(z | x_i, u) * p(x_i | u, x_j)\n",
    "                                v_new[idx][u][z][i] += v.v[i] * o[u][i][z] * t[u][j][i]\n",
    "                idx += 1\n",
    "            # add (|A| * |V|^|Z|) alpha-vectors to gamma, |V| is |gamma_k|\n",
    "            for u in range(actions):\n",
    "                c = self.compute_indices(idx, observations)\n",
    "                for indices in c:  # n elements in c is |V|^|Z|\n",
    "                    for z in range(observations):\n",
    "                        temp = np.zeros(states)\n",
    "                        for i in range(states):\n",
    "                            temp[i] = discount * (r[u][i] + v_new[indices[z]][u][z][i])\n",
    "                        gamma_k.add(AlphaVector(a=u, v=temp))\n",
    "            self.gamma.update(gamma_k)\n",
    "            if first:\n",
    "                # remove the dummy alpha vector\n",
    "                self.gamma.remove(dummy)\n",
    "                first = False\n",
    "            self.prune(states)\n",
    "            #  plot_gamma(title='V(b) for horizon T = ' + str(k + 1), self.gamma)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_indices(k, m):\n",
    "        \"\"\"\n",
    "        Compute all orderings of m elements with values between [0, k-1]\n",
    "        :param k: Number of alpha-vectors\n",
    "        :param m: Number of observations\n",
    "        :return: list of lists, where each list contains m elements, and each element is in [0, k-1].\n",
    "        Total should be k^m elements\n",
    "        \"\"\"\n",
    "        x = list(range(k))\n",
    "        return [p for p in product(x, repeat=m)]\n",
    "\n",
    "    def prune(self, n_states):\n",
    "        \"\"\"\n",
    "        Remove dominated alpha-vectors using Lark's filtering algorithm\n",
    "        :param n_states\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # parameters for linear program\n",
    "        delta = 0.0000000001\n",
    "        # equality constraints on the belief states\n",
    "        A_eq = np.array([np.append(np.ones(n_states), [0.])])\n",
    "        b_eq = np.array([1.])\n",
    "\n",
    "        # dirty set\n",
    "        F = self.gamma.copy()\n",
    "        # clean set\n",
    "        Q = set()\n",
    "\n",
    "        for i in range(n_states):\n",
    "            max_i = -np.inf\n",
    "            best = None\n",
    "            for av in F:\n",
    "                if av.v[i] > max_i:\n",
    "                    max_i = av.v[i]\n",
    "                    best = av\n",
    "            Q.update({best})\n",
    "            F.remove(best)\n",
    "        while F:\n",
    "            av_i = F.pop()  # get a reference to av_i\n",
    "            F.add(av_i)  # don't want to remove it yet from F\n",
    "            dominated = False\n",
    "            for av_j in Q:\n",
    "                c = np.append(np.zeros(n_states), [1.])\n",
    "                A_ub = np.array([np.append(-(av_i.v - av_j.v), [-1.])])\n",
    "                b_ub = np.array([-delta])\n",
    "\n",
    "                res = linprog(c, A_eq=A_eq, b_eq=b_eq, A_ub=A_ub, b_ub=b_ub, bounds=(0, None))\n",
    "                if res.x[n_states] > 0.0:\n",
    "                    # this one is dominated\n",
    "                    dominated = True\n",
    "                    F.remove(av_i)\n",
    "                    break\n",
    "\n",
    "            if not dominated:\n",
    "                max_k = -np.inf\n",
    "                best = None\n",
    "                for av_k in F:\n",
    "                    b = res.x[0:2]\n",
    "                    v = np.dot(av_k.v, b)\n",
    "                    if v > max_k:\n",
    "                        max_k = v\n",
    "                        best = av_k\n",
    "                F.remove(best)\n",
    "                if not self.check_duplicate(Q, best):\n",
    "                    Q.update({best})\n",
    "        self.gamma = Q\n",
    "\n",
    "    @staticmethod\n",
    "    def check_duplicate(a, av):\n",
    "        \"\"\"\n",
    "        Check whether alpha vector av is already in set a\n",
    "\n",
    "        :param a:\n",
    "        :param av:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for av_i in a:\n",
    "            if np.allclose(av_i.v, av.v):\n",
    "                return True\n",
    "            if av_i.v[0] == av.v[0] and av_i.v[1] > av.v[1]:\n",
    "                return True\n",
    "            if av_i.v[1] == av.v[1] and av_i.v[0] > av.v[0]:\n",
    "                return True\n",
    "\n",
    "    @staticmethod\n",
    "    def select_action(belief, vector_set):\n",
    "        \"\"\"\n",
    "        Compute optimal action given a belief distribution\n",
    "        :param belief: dim(belief) == dim(AlphaVector)\n",
    "        :param vector_set\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        max_v = -np.inf\n",
    "        best = None\n",
    "        for av in vector_set:\n",
    "            v = np.dot(av.v, belief)\n",
    "\n",
    "            if v > max_v:\n",
    "                max_v = v\n",
    "                best = av\n",
    "\n",
    "        if best is None:\n",
    "            raise ValueError('Vector set should not be empty')\n",
    "\n",
    "        return best.action, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', '1', '2', '3')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pomdp = POMDP(actions, t_prob, e_prob, rewards, states, discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp_solve = ValueIteration(pomdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'0': [array([ 219.62145794,   87.04320423,  -58.95578452, -185.0924472 ])]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility = pomdp_value_iteration(pomdp, epsilon=3)\n",
    "utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>204.525160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>88.982036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-34.290243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-171.265281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  204.525160\n",
       "1   88.982036\n",
       "2  -34.290243\n",
       "3 -171.265281"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([204.52516018,   88.9820356 ,  -34.29024281, -171.26528113]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADQRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yannik/miniconda3/envs/custom_hmm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These lines establish the feed-forward part of the network used to choose actions\n",
    "inputs1 = tf.placeholder(shape=[1,13],dtype=tf.float32)\n",
    "W = tf.Variable(tf.random_uniform([13,2],0,0.01))\n",
    "Qout = tf.matmul(inputs1,W)\n",
    "predict = tf.argmax(Qout,1)\n",
    "\n",
    "#Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "nextQ = tf.placeholder(shape=[1,2],dtype=tf.float32)\n",
    "loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "updateModel = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(obs):\n",
    "    state = 0\n",
    "    diff = 16\n",
    "    for i in range(len(statemean)):\n",
    "        stateDiff = obs - statemean[i]\n",
    "        stateDiffVal = np.sqrt(np.mean(stateDiff**2))\n",
    "        if stateDiffVal < diff:\n",
    "            diff = stateDiffVal\n",
    "            state = i\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the next step after an action is done\n",
    "\n",
    "def getStepDetails(i,j,action):\n",
    "    unitData = dataT_cycles[i]\n",
    "    d = False\n",
    "    if action == 1:\n",
    "        newJ = 0\n",
    "    else:\n",
    "        newJ = j+1\n",
    "    obsNext = unitData.values[newJ]\n",
    "    if newJ >= len(unitData) - 1:\n",
    "        d = True\n",
    "    s1 = get_state(obsNext)\n",
    "    r1 = rewards[action][s1]\n",
    "    return r1,newJ,s1,obsNext,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set learning parameters\n",
    "init = tf.global_variables_initializer()\n",
    "y = discount\n",
    "e = 0.1\n",
    "num_episodes = len(dataT_cycles)\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "D = np.empty([0,5]) # Replay memory\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        #Reset environment and get first new observation for new unit\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        k = 0\n",
    "        unitData = dataT_cycles[i]\n",
    "        #The Q-Network\n",
    "        while j < len(unitData):\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            a,allQ = sess.run([predict,Qout],feed_dict={inputs1:unitData.values[j].reshape(1,13)})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = np.random.randint(0,2)\n",
    "            #Get new state and reward from environment\n",
    "            r,j,s1,o1,d = getStepDetails(i,j,a[0])\n",
    "            D = np.vstack([D, [a[0],unitData.values[j-1].reshape(1,13),r,o1,s1]])\n",
    "            if len(D) > 20:\n",
    "                lastInd = np.random.randint(15,len(D))\n",
    "                randomSample = D[lastInd-15:lastInd]\n",
    "                finalO = D[lastInd,3].reshape(1,13)\n",
    "                Reward = np.sum(D[lastInd-15:lastInd,2])\n",
    "            else:\n",
    "                finalO = o1.reshape(1,13)\n",
    "                Reward = r\n",
    "            # We take batch size of 15 (j in algorithm)\n",
    "            #Obtain the Q' values by feeding the new state through our network\n",
    "            Q1 = sess.run(Qout,feed_dict={inputs1:finalO})\n",
    "            #Obtain maxQ' and set our target value for chosen action.\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0,a[0]] = Reward + y*maxQ1\n",
    "            #Train our network using target and predicted Q values\n",
    "            _,W1 = sess.run([updateModel,W],feed_dict={inputs1:unitData.values[j-1].reshape(1,13),nextQ:targetQ})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            k += 1\n",
    "            if d == True or k >= 1000:\n",
    "                #Reduce chance of random action as we train the model.\n",
    "                e = 1./((i/50) + 10)\n",
    "                break\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataT_cycles[5].values[160].reshape(-1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77108434, 0.48484848, 0.40257649, 0.51515152, 0.03688414,\n",
       "       0.61904762, 0.36886994, 0.55882353, 0.03333677, 0.65101962,\n",
       "       0.58333333, 0.30232558, 0.2903894 ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataT_cycles[5].values[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2364.409  , 5880.967  ],\n",
       "       [1871.21   , 5603.3594 ],\n",
       "       [3616.782  , 4988.657  ],\n",
       "       [4809.125  ,  873.2698 ],\n",
       "       [3126.0398 ,   76.49012],\n",
       "       [3813.273  , 3731.947  ],\n",
       "       [5509.8306 , 1830.7938 ],\n",
       "       [4643.098  ,  543.59045],\n",
       "       [8576.893  ,  -95.22542],\n",
       "       [2755.4534 , 2314.9817 ],\n",
       "       [2022.7578 , 2662.1064 ],\n",
       "       [4247.6187 , 1322.4498 ],\n",
       "       [2997.3079 , 1125.1122 ]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19181.12600722, 16785.20466186]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate that my modified HMM approach does well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "startprob = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "# The transition matrix\n",
    "transmat = np.array([[0.5, 0.5, 0.        , 0.        ],\n",
    "       [0.        , 0.7, 0.3, 0.        ],\n",
    "       [0.        , 0.        , 0.7, 0.3],\n",
    "       [0.        , 0.        , 0.        , 1.        ]])\n",
    "# The means of each component\n",
    "means = np.array([[0.0],\n",
    "                  [2.0],\n",
    "                  [4.0],\n",
    "                  [6.0]])\n",
    "# The covariance of each component\n",
    "covars = .5 * np.tile(np.identity(1), (4, 1, 1))\n",
    "\n",
    "# Build an HMM instance and set parameters\n",
    "model = hmm.GaussianHMM(n_components=4, covariance_type=\"full\")\n",
    "\n",
    "# Instead of fitting it from the data, we directly set the estimated\n",
    "# parameters, the means and covariance of the components\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.means_ = means\n",
    "model.covars_ = covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "X, Z = model.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35602697],\n",
       "       [3.08790577],\n",
       "       [0.73113541],\n",
       "       [3.74176709],\n",
       "       [6.33186839],\n",
       "       [5.26252865],\n",
       "       [5.81617712],\n",
       "       [5.95034963],\n",
       "       [6.32155638],\n",
       "       [5.57562802],\n",
       "       [6.57786684],\n",
       "       [5.21767187],\n",
       "       [5.71624018],\n",
       "       [6.56936107],\n",
       "       [6.36872761],\n",
       "       [7.18465807],\n",
       "       [6.33123111],\n",
       "       [5.42487311],\n",
       "       [5.66031572],\n",
       "       [5.59866474],\n",
       "       [7.14676289],\n",
       "       [5.96983072],\n",
       "       [5.25250824],\n",
       "       [6.03219877],\n",
       "       [5.81217605],\n",
       "       [6.20817946],\n",
       "       [6.65235542],\n",
       "       [5.13525054],\n",
       "       [5.98594575],\n",
       "       [6.33139403],\n",
       "       [6.35935308],\n",
       "       [5.40713059],\n",
       "       [4.10167391],\n",
       "       [5.21723258],\n",
       "       [5.54798005],\n",
       "       [6.2406278 ],\n",
       "       [7.12127763],\n",
       "       [7.12956194],\n",
       "       [5.86190312],\n",
       "       [6.90007406],\n",
       "       [5.49058033],\n",
       "       [6.12213372],\n",
       "       [5.76408937],\n",
       "       [6.71847846],\n",
       "       [6.05110877],\n",
       "       [5.29446107],\n",
       "       [6.27292152],\n",
       "       [5.59903468],\n",
       "       [7.07709373],\n",
       "       [5.89661231],\n",
       "       [5.62119269],\n",
       "       [6.29184358],\n",
       "       [6.28143619],\n",
       "       [5.73301061],\n",
       "       [6.01744521],\n",
       "       [6.01454093],\n",
       "       [6.82441177],\n",
       "       [5.78703959],\n",
       "       [7.06507788],\n",
       "       [5.27446398],\n",
       "       [6.5059673 ],\n",
       "       [5.90082007],\n",
       "       [6.53450884],\n",
       "       [5.32782984],\n",
       "       [5.72160932],\n",
       "       [6.51355514],\n",
       "       [7.02844386],\n",
       "       [5.74363225],\n",
       "       [4.60248084],\n",
       "       [5.2375394 ],\n",
       "       [6.0529612 ],\n",
       "       [5.69734891],\n",
       "       [6.2410304 ],\n",
       "       [5.89861118],\n",
       "       [6.88828561],\n",
       "       [6.51581099],\n",
       "       [5.8424212 ],\n",
       "       [4.17671272],\n",
       "       [6.58278393],\n",
       "       [6.96465848],\n",
       "       [7.34940353],\n",
       "       [6.14930437],\n",
       "       [5.00381808],\n",
       "       [6.86096681],\n",
       "       [5.9025473 ],\n",
       "       [4.45622717],\n",
       "       [6.25676741],\n",
       "       [6.72797729],\n",
       "       [6.70797629],\n",
       "       [6.99381815],\n",
       "       [5.55282673],\n",
       "       [6.51334682],\n",
       "       [5.28323627],\n",
       "       [5.87266438],\n",
       "       [5.94637798],\n",
       "       [6.1942188 ],\n",
       "       [6.12291581],\n",
       "       [6.30430448],\n",
       "       [6.17370912],\n",
       "       [6.2898682 ],\n",
       "       [6.25018471],\n",
       "       [6.15706008],\n",
       "       [6.23922583],\n",
       "       [5.73799253],\n",
       "       [5.88444231],\n",
       "       [6.83075617],\n",
       "       [7.37745343],\n",
       "       [6.59273856],\n",
       "       [6.51898819],\n",
       "       [6.42436374],\n",
       "       [6.77707264],\n",
       "       [6.03497014],\n",
       "       [6.31466423],\n",
       "       [5.56917792],\n",
       "       [6.40960332],\n",
       "       [6.1802261 ],\n",
       "       [6.08472161],\n",
       "       [5.13331573],\n",
       "       [6.00962641],\n",
       "       [4.45911177],\n",
       "       [5.65251295],\n",
       "       [5.95642423],\n",
       "       [6.10441089],\n",
       "       [4.88224973],\n",
       "       [6.69093956],\n",
       "       [5.53388184],\n",
       "       [6.16089778],\n",
       "       [6.13311888],\n",
       "       [5.16454483],\n",
       "       [5.99389839],\n",
       "       [5.75861308],\n",
       "       [5.94174128],\n",
       "       [4.44619576],\n",
       "       [6.36400597],\n",
       "       [5.87399462],\n",
       "       [6.14517717],\n",
       "       [7.12336061],\n",
       "       [5.80123362],\n",
       "       [5.30737007],\n",
       "       [6.45749162],\n",
       "       [6.13956034],\n",
       "       [5.31072192],\n",
       "       [5.29828894],\n",
       "       [5.14612914],\n",
       "       [7.10875054],\n",
       "       [6.43903732],\n",
       "       [6.26885795],\n",
       "       [5.48064311],\n",
       "       [6.58541772],\n",
       "       [5.49793754],\n",
       "       [5.80926809],\n",
       "       [5.07629425],\n",
       "       [6.07778576],\n",
       "       [4.79674874],\n",
       "       [5.91167236],\n",
       "       [5.67728857],\n",
       "       [5.58079443],\n",
       "       [4.70190966],\n",
       "       [4.83364131],\n",
       "       [5.96008646],\n",
       "       [5.66534077],\n",
       "       [6.54074982],\n",
       "       [5.1753251 ],\n",
       "       [6.35846048],\n",
       "       [5.95104879],\n",
       "       [5.36556249],\n",
       "       [5.26601245],\n",
       "       [6.58175939],\n",
       "       [6.38179028],\n",
       "       [5.50308646],\n",
       "       [5.21264991],\n",
       "       [6.76725268],\n",
       "       [5.74804039],\n",
       "       [4.56528631],\n",
       "       [6.96363671],\n",
       "       [5.53890536],\n",
       "       [7.04989084],\n",
       "       [6.93019782],\n",
       "       [7.0111747 ],\n",
       "       [6.760599  ],\n",
       "       [5.26469981],\n",
       "       [5.95860411],\n",
       "       [5.40672003],\n",
       "       [6.4274614 ],\n",
       "       [5.77031627],\n",
       "       [5.67375779],\n",
       "       [5.45509571],\n",
       "       [6.53910896],\n",
       "       [5.87406332],\n",
       "       [6.28963572],\n",
       "       [6.1336802 ],\n",
       "       [5.70431836],\n",
       "       [5.92864131],\n",
       "       [5.93052507],\n",
       "       [5.79454943],\n",
       "       [5.72168308],\n",
       "       [4.1585853 ],\n",
       "       [6.70159106],\n",
       "       [6.09873468],\n",
       "       [5.42621358],\n",
       "       [4.98619879],\n",
       "       [5.08787263],\n",
       "       [6.7493295 ],\n",
       "       [7.78049519],\n",
       "       [5.50767714],\n",
       "       [6.59004158],\n",
       "       [6.48621666],\n",
       "       [6.50000416],\n",
       "       [6.25828422],\n",
       "       [6.26324435],\n",
       "       [5.13489619],\n",
       "       [6.23376347],\n",
       "       [5.48163694],\n",
       "       [5.72909866],\n",
       "       [6.90992275],\n",
       "       [5.95704899],\n",
       "       [6.84656725],\n",
       "       [5.12612698],\n",
       "       [6.87697502],\n",
       "       [5.84191143],\n",
       "       [5.93326961],\n",
       "       [4.31060648],\n",
       "       [5.24053128],\n",
       "       [5.82541873],\n",
       "       [6.08243119],\n",
       "       [7.0986744 ],\n",
       "       [5.73617049],\n",
       "       [7.00075906],\n",
       "       [5.21961382],\n",
       "       [5.02784224],\n",
       "       [6.95530365],\n",
       "       [5.60071707],\n",
       "       [6.64023549],\n",
       "       [4.93903349],\n",
       "       [6.03192565],\n",
       "       [5.71816881],\n",
       "       [5.38177128],\n",
       "       [6.42480762],\n",
       "       [5.68307305],\n",
       "       [6.09799323],\n",
       "       [6.3390981 ],\n",
       "       [6.13596263],\n",
       "       [6.245152  ],\n",
       "       [6.02762946],\n",
       "       [5.86683165],\n",
       "       [5.25474454],\n",
       "       [5.73049513],\n",
       "       [5.8584854 ],\n",
       "       [6.56521904],\n",
       "       [6.51956646],\n",
       "       [7.28396564],\n",
       "       [5.12075377],\n",
       "       [6.34107218],\n",
       "       [4.78481808],\n",
       "       [6.21544231],\n",
       "       [5.28741497],\n",
       "       [5.9208273 ],\n",
       "       [5.63148024],\n",
       "       [4.61064658],\n",
       "       [5.48402047],\n",
       "       [5.53284837],\n",
       "       [4.83602014],\n",
       "       [6.27910815],\n",
       "       [5.17437231],\n",
       "       [6.10845963],\n",
       "       [6.0418174 ],\n",
       "       [6.12595009],\n",
       "       [6.71844096],\n",
       "       [6.40394453],\n",
       "       [6.72485758],\n",
       "       [6.87092143],\n",
       "       [7.20849068],\n",
       "       [6.15267648],\n",
       "       [5.1943116 ],\n",
       "       [8.07115965],\n",
       "       [5.53688912],\n",
       "       [5.93573124],\n",
       "       [5.90101201],\n",
       "       [4.47084702],\n",
       "       [5.42918351],\n",
       "       [7.29052871],\n",
       "       [6.17098251],\n",
       "       [5.67181123],\n",
       "       [6.34258081],\n",
       "       [7.40838997],\n",
       "       [5.16895037],\n",
       "       [5.69315738],\n",
       "       [5.95343346],\n",
       "       [6.06955643],\n",
       "       [6.05667989],\n",
       "       [5.47302304],\n",
       "       [4.87090789],\n",
       "       [5.80672653],\n",
       "       [4.75238515],\n",
       "       [5.23527886],\n",
       "       [4.56190619],\n",
       "       [7.4546453 ],\n",
       "       [5.29967522],\n",
       "       [5.59825776],\n",
       "       [5.34307582],\n",
       "       [7.29115934],\n",
       "       [5.84122801],\n",
       "       [6.25497754],\n",
       "       [6.55130819],\n",
       "       [5.85853646],\n",
       "       [6.16620485],\n",
       "       [5.53200274],\n",
       "       [5.03003786],\n",
       "       [6.01992388],\n",
       "       [6.28296019],\n",
       "       [5.70809717],\n",
       "       [7.52592966],\n",
       "       [5.67850444],\n",
       "       [4.54162853],\n",
       "       [7.51229544],\n",
       "       [6.78123865],\n",
       "       [6.37061394],\n",
       "       [6.03593197],\n",
       "       [5.72902763],\n",
       "       [6.90598515],\n",
       "       [6.19940534],\n",
       "       [6.86846183],\n",
       "       [6.93350422],\n",
       "       [5.68088643],\n",
       "       [6.02819918],\n",
       "       [6.76280401],\n",
       "       [6.31725119],\n",
       "       [5.72302991],\n",
       "       [6.49009665],\n",
       "       [6.6149404 ],\n",
       "       [6.13965496],\n",
       "       [6.90834749],\n",
       "       [6.9764679 ],\n",
       "       [7.39781621],\n",
       "       [5.10963759],\n",
       "       [5.47094905],\n",
       "       [6.19235853],\n",
       "       [6.04013156],\n",
       "       [4.91176899],\n",
       "       [4.64605006],\n",
       "       [5.83854597],\n",
       "       [5.704162  ],\n",
       "       [5.89659182],\n",
       "       [5.38013006],\n",
       "       [6.3831679 ],\n",
       "       [5.27194844],\n",
       "       [4.48828596],\n",
       "       [5.2222374 ],\n",
       "       [6.19814041],\n",
       "       [5.76804506],\n",
       "       [5.59295193],\n",
       "       [6.89752096],\n",
       "       [5.85620767],\n",
       "       [8.19171323],\n",
       "       [5.996674  ],\n",
       "       [5.99515349],\n",
       "       [5.45807018],\n",
       "       [6.29282704],\n",
       "       [5.43159728],\n",
       "       [4.53544563],\n",
       "       [6.84821579],\n",
       "       [6.05428402],\n",
       "       [6.18452503],\n",
       "       [6.79145622],\n",
       "       [5.87857247],\n",
       "       [6.37374354],\n",
       "       [6.59623371],\n",
       "       [6.73800711],\n",
       "       [5.21245684],\n",
       "       [5.92367546],\n",
       "       [6.05961432],\n",
       "       [6.20045738],\n",
       "       [5.8737833 ],\n",
       "       [5.58856744],\n",
       "       [6.12922092],\n",
       "       [5.79442387],\n",
       "       [6.4227301 ],\n",
       "       [7.1336786 ],\n",
       "       [7.20130031],\n",
       "       [5.75565327],\n",
       "       [6.21786217],\n",
       "       [5.42206696],\n",
       "       [6.77364802],\n",
       "       [6.57101534],\n",
       "       [5.68551788],\n",
       "       [7.34482768],\n",
       "       [5.79910634],\n",
       "       [6.79420396],\n",
       "       [6.93678478],\n",
       "       [6.07680792],\n",
       "       [5.20797078],\n",
       "       [5.52015694],\n",
       "       [4.98271577],\n",
       "       [5.52075441],\n",
       "       [5.19950785],\n",
       "       [5.86613112],\n",
       "       [6.21965716],\n",
       "       [5.96540255],\n",
       "       [5.69560863],\n",
       "       [6.72277437],\n",
       "       [6.27569916],\n",
       "       [5.33554056],\n",
       "       [7.06776176],\n",
       "       [5.75137281],\n",
       "       [5.60820487],\n",
       "       [5.84090975],\n",
       "       [5.20710479],\n",
       "       [5.96769907],\n",
       "       [6.85402366],\n",
       "       [5.7824062 ],\n",
       "       [6.74567049],\n",
       "       [6.38493159],\n",
       "       [5.75355202],\n",
       "       [6.59889308],\n",
       "       [5.47419081],\n",
       "       [5.73620893],\n",
       "       [6.40894407],\n",
       "       [5.55781293],\n",
       "       [5.76932347],\n",
       "       [5.37048388],\n",
       "       [6.06062804],\n",
       "       [5.32672018],\n",
       "       [5.96223564],\n",
       "       [6.54302965],\n",
       "       [5.25946284],\n",
       "       [5.59148254],\n",
       "       [5.29039897],\n",
       "       [6.99092591],\n",
       "       [6.17340415],\n",
       "       [6.11274911],\n",
       "       [6.40852471],\n",
       "       [6.04045748],\n",
       "       [6.07187843],\n",
       "       [5.1563466 ],\n",
       "       [6.18305759],\n",
       "       [5.48386517],\n",
       "       [7.41753749],\n",
       "       [4.81440757],\n",
       "       [5.30669141],\n",
       "       [6.76175134],\n",
       "       [5.59100062],\n",
       "       [6.25047664],\n",
       "       [6.2389086 ],\n",
       "       [5.65306164],\n",
       "       [6.73748355],\n",
       "       [5.87932999],\n",
       "       [6.5697404 ],\n",
       "       [6.09925178],\n",
       "       [5.72978849],\n",
       "       [6.74598136],\n",
       "       [6.26391018],\n",
       "       [5.72273797],\n",
       "       [4.92037376],\n",
       "       [5.23106255],\n",
       "       [5.85624502],\n",
       "       [7.35199185],\n",
       "       [7.41071071],\n",
       "       [6.02787654],\n",
       "       [6.92081534],\n",
       "       [6.93840335],\n",
       "       [6.6485995 ],\n",
       "       [6.32540073],\n",
       "       [6.96601813],\n",
       "       [6.4705347 ],\n",
       "       [6.10826447],\n",
       "       [6.83399868],\n",
       "       [6.15394553],\n",
       "       [7.27884647],\n",
       "       [5.01690481],\n",
       "       [6.54193756],\n",
       "       [6.41094839],\n",
       "       [6.07641166],\n",
       "       [5.42124329],\n",
       "       [5.53757857],\n",
       "       [5.56175568],\n",
       "       [5.89345667],\n",
       "       [7.13127714],\n",
       "       [6.27681442],\n",
       "       [5.83423325],\n",
       "       [6.55554803],\n",
       "       [5.74281486],\n",
       "       [7.28782697],\n",
       "       [6.89174069],\n",
       "       [6.64713186],\n",
       "       [7.1400839 ],\n",
       "       [7.48603959],\n",
       "       [6.52791733],\n",
       "       [6.21214354],\n",
       "       [6.07837884],\n",
       "       [6.65487471],\n",
       "       [7.2750723 ],\n",
       "       [6.34184506],\n",
       "       [6.15764148],\n",
       "       [5.14503815],\n",
       "       [6.50119282],\n",
       "       [6.39928549],\n",
       "       [7.07602697],\n",
       "       [6.96988043],\n",
       "       [4.54796242],\n",
       "       [5.60228316],\n",
       "       [5.8846502 ],\n",
       "       [5.59166562],\n",
       "       [6.5185054 ],\n",
       "       [5.89934847],\n",
       "       [6.61966872],\n",
       "       [5.05356432],\n",
       "       [4.46756511],\n",
       "       [5.78239337],\n",
       "       [5.32790766],\n",
       "       [6.83327818],\n",
       "       [6.78590717],\n",
       "       [7.69058678],\n",
       "       [7.05678839],\n",
       "       [4.68676837],\n",
       "       [6.30537693],\n",
       "       [4.72839708],\n",
       "       [6.4120844 ],\n",
       "       [6.27563912],\n",
       "       [7.71578812],\n",
       "       [6.25459443],\n",
       "       [6.20431254],\n",
       "       [5.99866581],\n",
       "       [5.5104886 ],\n",
       "       [5.26208877],\n",
       "       [6.39284603],\n",
       "       [6.07130219],\n",
       "       [5.44298654],\n",
       "       [6.88707545],\n",
       "       [5.96822153],\n",
       "       [5.4135655 ],\n",
       "       [6.41458126],\n",
       "       [6.28781898],\n",
       "       [4.84426948],\n",
       "       [5.88069175],\n",
       "       [6.50236853],\n",
       "       [4.92021158],\n",
       "       [5.45645896],\n",
       "       [6.43160239],\n",
       "       [5.636787  ],\n",
       "       [5.99814004],\n",
       "       [4.50553979],\n",
       "       [6.94516724],\n",
       "       [6.08013467],\n",
       "       [5.57217772],\n",
       "       [5.02982051],\n",
       "       [6.99160518],\n",
       "       [6.03061788],\n",
       "       [6.72570604],\n",
       "       [6.0694623 ],\n",
       "       [6.61662778],\n",
       "       [7.18262605],\n",
       "       [5.97731464],\n",
       "       [5.75883244],\n",
       "       [6.69845372],\n",
       "       [6.0405435 ],\n",
       "       [6.2320063 ],\n",
       "       [6.7350655 ],\n",
       "       [6.08563484],\n",
       "       [6.57511048],\n",
       "       [6.16001342],\n",
       "       [6.20824895],\n",
       "       [6.11309901],\n",
       "       [6.55076105],\n",
       "       [5.06068468],\n",
       "       [6.18524731],\n",
       "       [4.82021205],\n",
       "       [7.03542174],\n",
       "       [6.7937562 ],\n",
       "       [5.70484014],\n",
       "       [5.47152282],\n",
       "       [6.57079251],\n",
       "       [6.89555463],\n",
       "       [5.20897099],\n",
       "       [5.20031015],\n",
       "       [4.4626488 ],\n",
       "       [5.66345256],\n",
       "       [5.81684161],\n",
       "       [5.87179228],\n",
       "       [4.94533317],\n",
       "       [6.03304317],\n",
       "       [6.39241347],\n",
       "       [5.79377212],\n",
       "       [6.04273308],\n",
       "       [5.42245321],\n",
       "       [6.58520736],\n",
       "       [5.92153139],\n",
       "       [5.40847106],\n",
       "       [6.57778581],\n",
       "       [5.50935824],\n",
       "       [5.46905048],\n",
       "       [4.56124846],\n",
       "       [6.35710895],\n",
       "       [5.65351061],\n",
       "       [5.84834323],\n",
       "       [5.44659814],\n",
       "       [5.38092968],\n",
       "       [5.61628267],\n",
       "       [5.81903351],\n",
       "       [5.81898453],\n",
       "       [6.82887799],\n",
       "       [6.86371802],\n",
       "       [7.35037682],\n",
       "       [5.34332901],\n",
       "       [6.26043651],\n",
       "       [5.06363674],\n",
       "       [6.31929212],\n",
       "       [6.04205741],\n",
       "       [7.72149893],\n",
       "       [4.92264313],\n",
       "       [6.12526061],\n",
       "       [5.25378018],\n",
       "       [6.0544331 ],\n",
       "       [5.8036798 ],\n",
       "       [5.54532629],\n",
       "       [5.60992361],\n",
       "       [6.69919514],\n",
       "       [6.26242706],\n",
       "       [6.08746262],\n",
       "       [6.28082363],\n",
       "       [6.82336581],\n",
       "       [6.49265097],\n",
       "       [6.4889455 ],\n",
       "       [4.26839922],\n",
       "       [5.88151343],\n",
       "       [6.30284339],\n",
       "       [5.58174962],\n",
       "       [6.30090328],\n",
       "       [5.5173483 ],\n",
       "       [7.03019254],\n",
       "       [5.25841319],\n",
       "       [6.07395484],\n",
       "       [5.52466669],\n",
       "       [4.81782605],\n",
       "       [5.06656704],\n",
       "       [6.46055076],\n",
       "       [4.77191432],\n",
       "       [6.72922613],\n",
       "       [4.77887682],\n",
       "       [6.35499778],\n",
       "       [6.44566492],\n",
       "       [4.74952117],\n",
       "       [6.8017264 ],\n",
       "       [5.33672614],\n",
       "       [6.82463967],\n",
       "       [4.5218331 ],\n",
       "       [5.3556456 ],\n",
       "       [5.15025665],\n",
       "       [5.75281502],\n",
       "       [5.39374648],\n",
       "       [6.61560467],\n",
       "       [6.43377398],\n",
       "       [5.58204424],\n",
       "       [6.45562013],\n",
       "       [5.43809208],\n",
       "       [7.07105341],\n",
       "       [5.87156024],\n",
       "       [5.67440897],\n",
       "       [5.84253769],\n",
       "       [6.13091578],\n",
       "       [5.71849096],\n",
       "       [5.8672879 ],\n",
       "       [7.19020318],\n",
       "       [5.2979072 ],\n",
       "       [6.14082402],\n",
       "       [4.31590865],\n",
       "       [5.41739418],\n",
       "       [4.82299586],\n",
       "       [5.84519324],\n",
       "       [5.19163323],\n",
       "       [6.57513166],\n",
       "       [6.39989511],\n",
       "       [5.60661415],\n",
       "       [7.09753885],\n",
       "       [5.73093846],\n",
       "       [5.99032164],\n",
       "       [5.92623968],\n",
       "       [6.09168676],\n",
       "       [4.40713248],\n",
       "       [5.42286965],\n",
       "       [7.37618351],\n",
       "       [5.52487327],\n",
       "       [5.80329769],\n",
       "       [5.86090653],\n",
       "       [5.97196522],\n",
       "       [5.81708335],\n",
       "       [6.05363318],\n",
       "       [5.14748982],\n",
       "       [6.23260324],\n",
       "       [5.25789899],\n",
       "       [5.54277908],\n",
       "       [6.48569942],\n",
       "       [4.66835064],\n",
       "       [6.53735029],\n",
       "       [3.74032325],\n",
       "       [6.29563405],\n",
       "       [6.33872303],\n",
       "       [6.09753946],\n",
       "       [6.45748999],\n",
       "       [5.69237265],\n",
       "       [6.54817515],\n",
       "       [6.23584503],\n",
       "       [6.16767244],\n",
       "       [5.59408172],\n",
       "       [6.18853598],\n",
       "       [5.7154741 ],\n",
       "       [6.14404255],\n",
       "       [5.13640508],\n",
       "       [5.33201278],\n",
       "       [6.18106658],\n",
       "       [6.24637171],\n",
       "       [6.38468176],\n",
       "       [6.18542454],\n",
       "       [6.76300394],\n",
       "       [6.51141861],\n",
       "       [7.02769176],\n",
       "       [5.06165856],\n",
       "       [6.56685218],\n",
       "       [5.36598882],\n",
       "       [7.22122706],\n",
       "       [5.72744103],\n",
       "       [8.0747081 ],\n",
       "       [5.34217061],\n",
       "       [5.15382188],\n",
       "       [5.45672366],\n",
       "       [5.81983264],\n",
       "       [5.61961918],\n",
       "       [6.40820161],\n",
       "       [4.87004448],\n",
       "       [5.92208251],\n",
       "       [6.48932935],\n",
       "       [5.93829333],\n",
       "       [5.71630515],\n",
       "       [5.25857181],\n",
       "       [5.38443773],\n",
       "       [6.48034573],\n",
       "       [5.57741934],\n",
       "       [5.32248351],\n",
       "       [6.0370483 ],\n",
       "       [7.26300773],\n",
       "       [5.80234388],\n",
       "       [4.90521581],\n",
       "       [5.5448112 ],\n",
       "       [6.32089323],\n",
       "       [5.90071838],\n",
       "       [4.78365256],\n",
       "       [5.12536033],\n",
       "       [7.09779633],\n",
       "       [7.17654166],\n",
       "       [4.21909851],\n",
       "       [4.55820266],\n",
       "       [5.52144998],\n",
       "       [6.69213132],\n",
       "       [5.62079751],\n",
       "       [4.98633093],\n",
       "       [6.40344431],\n",
       "       [5.92819   ],\n",
       "       [6.55224035],\n",
       "       [5.6838717 ],\n",
       "       [5.86879067],\n",
       "       [5.98138862],\n",
       "       [6.84495359],\n",
       "       [6.70234226],\n",
       "       [5.39542413],\n",
       "       [7.591753  ],\n",
       "       [7.19572397],\n",
       "       [4.78815753],\n",
       "       [6.01160719],\n",
       "       [5.54882782],\n",
       "       [5.73953477],\n",
       "       [6.85022202],\n",
       "       [5.85442323],\n",
       "       [6.25018762],\n",
       "       [5.78709702],\n",
       "       [5.04805421],\n",
       "       [5.35104449],\n",
       "       [5.56645327],\n",
       "       [6.40241278],\n",
       "       [5.93463715],\n",
       "       [6.76617035],\n",
       "       [6.05620477],\n",
       "       [6.3452238 ],\n",
       "       [5.58984072],\n",
       "       [5.73592349],\n",
       "       [5.33676647],\n",
       "       [5.80700974],\n",
       "       [5.71977385],\n",
       "       [5.9226631 ],\n",
       "       [5.83410681],\n",
       "       [5.85994855],\n",
       "       [5.37262993],\n",
       "       [6.35917687],\n",
       "       [6.67067815],\n",
       "       [6.48963892],\n",
       "       [6.05030081],\n",
       "       [6.0735322 ],\n",
       "       [5.37620827],\n",
       "       [6.48749911],\n",
       "       [6.76891068],\n",
       "       [6.34497952],\n",
       "       [6.98774199],\n",
       "       [5.16726534],\n",
       "       [5.80091521],\n",
       "       [5.00616134],\n",
       "       [5.74167513],\n",
       "       [5.57001516],\n",
       "       [5.22269523],\n",
       "       [4.97756404],\n",
       "       [5.42408215],\n",
       "       [5.88480111],\n",
       "       [7.39812067],\n",
       "       [4.64688956],\n",
       "       [6.44067546],\n",
       "       [5.75723757],\n",
       "       [5.49792243],\n",
       "       [6.62669176],\n",
       "       [7.51865629],\n",
       "       [7.29232793],\n",
       "       [6.71689227],\n",
       "       [6.91754508],\n",
       "       [4.5924274 ],\n",
       "       [5.84845868],\n",
       "       [6.03755078],\n",
       "       [6.52676103],\n",
       "       [6.24489408],\n",
       "       [5.70631653],\n",
       "       [6.10618647],\n",
       "       [6.54662623],\n",
       "       [6.35593139],\n",
       "       [5.75553   ],\n",
       "       [5.65059529],\n",
       "       [6.40185996],\n",
       "       [5.59168074],\n",
       "       [5.21701116],\n",
       "       [6.10772761],\n",
       "       [7.19935487],\n",
       "       [6.20913739],\n",
       "       [6.43232626],\n",
       "       [6.03515525],\n",
       "       [7.49037001],\n",
       "       [5.83311028],\n",
       "       [6.50570837],\n",
       "       [5.05003942],\n",
       "       [5.43044293],\n",
       "       [5.37632917],\n",
       "       [6.42427683],\n",
       "       [6.86209689],\n",
       "       [5.88158844],\n",
       "       [7.02366028],\n",
       "       [5.2456416 ],\n",
       "       [7.20444463],\n",
       "       [5.81556111],\n",
       "       [4.53475387],\n",
       "       [4.68455527],\n",
       "       [6.25020923],\n",
       "       [5.72850249],\n",
       "       [4.95534717],\n",
       "       [5.47854868],\n",
       "       [6.17294763],\n",
       "       [6.0448025 ],\n",
       "       [6.49021137],\n",
       "       [4.93856987],\n",
       "       [6.1685353 ],\n",
       "       [4.90790749],\n",
       "       [6.22312786],\n",
       "       [5.51091292],\n",
       "       [6.15606978],\n",
       "       [5.42978505],\n",
       "       [5.80872564],\n",
       "       [6.3169687 ],\n",
       "       [5.66360352],\n",
       "       [4.69752578],\n",
       "       [5.87231326],\n",
       "       [5.9644674 ],\n",
       "       [6.22866313],\n",
       "       [6.02780601],\n",
       "       [6.80748839],\n",
       "       [6.73795644],\n",
       "       [4.75984089],\n",
       "       [5.34450337],\n",
       "       [6.35309127],\n",
       "       [6.04373238],\n",
       "       [6.7832556 ],\n",
       "       [5.01841494],\n",
       "       [5.91882615],\n",
       "       [6.17100717],\n",
       "       [5.93077151],\n",
       "       [5.71943854],\n",
       "       [4.72630382],\n",
       "       [6.67944712],\n",
       "       [5.70786447],\n",
       "       [5.463667  ],\n",
       "       [6.73628729],\n",
       "       [7.74681212],\n",
       "       [6.58627787],\n",
       "       [5.99615751],\n",
       "       [5.07713467],\n",
       "       [5.5436544 ],\n",
       "       [6.22589102],\n",
       "       [5.47743916],\n",
       "       [5.34871999],\n",
       "       [5.45646084],\n",
       "       [5.65188457],\n",
       "       [5.94660978],\n",
       "       [6.43207685],\n",
       "       [5.11198662],\n",
       "       [6.38097461],\n",
       "       [6.3058531 ],\n",
       "       [6.12815036],\n",
       "       [6.48154809],\n",
       "       [6.32585929],\n",
       "       [4.752235  ],\n",
       "       [6.21538336],\n",
       "       [7.04351687],\n",
       "       [5.65608255],\n",
       "       [5.82448519],\n",
       "       [6.22466842],\n",
       "       [5.51446699],\n",
       "       [5.63917515],\n",
       "       [7.94603113],\n",
       "       [5.98077621],\n",
       "       [6.15702072],\n",
       "       [5.6293875 ],\n",
       "       [6.79012028],\n",
       "       [6.58530588],\n",
       "       [4.53097003],\n",
       "       [5.84466506],\n",
       "       [5.53142948],\n",
       "       [5.35205568],\n",
       "       [6.38496404],\n",
       "       [6.58709792],\n",
       "       [5.4391684 ],\n",
       "       [6.57162112],\n",
       "       [5.87386238],\n",
       "       [6.56116983],\n",
       "       [5.93192001],\n",
       "       [5.91469217],\n",
       "       [5.45938819],\n",
       "       [6.02192783],\n",
       "       [5.92619186],\n",
       "       [7.14182349],\n",
       "       [6.20344703],\n",
       "       [6.16851113],\n",
       "       [7.07954878],\n",
       "       [6.18246447],\n",
       "       [5.00341048],\n",
       "       [5.89909898],\n",
       "       [5.04064972],\n",
       "       [5.7336283 ],\n",
       "       [5.25794712],\n",
       "       [6.70513883],\n",
       "       [7.11621554],\n",
       "       [5.71702605],\n",
       "       [6.44353769],\n",
       "       [5.8332323 ],\n",
       "       [7.07129155],\n",
       "       [5.27991833],\n",
       "       [6.39730214],\n",
       "       [5.10199263],\n",
       "       [6.55487016],\n",
       "       [6.26700744],\n",
       "       [6.28195143],\n",
       "       [6.02687013],\n",
       "       [5.15851772],\n",
       "       [5.62394708],\n",
       "       [6.78468229],\n",
       "       [5.7034006 ],\n",
       "       [5.52458456],\n",
       "       [6.11361214],\n",
       "       [5.67851797],\n",
       "       [6.78869935],\n",
       "       [6.52156625],\n",
       "       [5.87436654],\n",
       "       [5.58538905],\n",
       "       [5.18537695],\n",
       "       [5.9482424 ],\n",
       "       [6.20919688],\n",
       "       [5.22165233],\n",
       "       [6.49000243],\n",
       "       [5.15169268],\n",
       "       [5.1254508 ],\n",
       "       [5.71698261],\n",
       "       [4.80623091],\n",
       "       [6.22392348],\n",
       "       [6.53463117],\n",
       "       [5.60544083],\n",
       "       [5.82945769],\n",
       "       [5.6339069 ],\n",
       "       [5.64196788],\n",
       "       [6.23065141],\n",
       "       [6.71934811],\n",
       "       [5.74695936],\n",
       "       [6.777791  ],\n",
       "       [6.17247228],\n",
       "       [5.65726596],\n",
       "       [5.86147437],\n",
       "       [5.56916777],\n",
       "       [4.17161611],\n",
       "       [6.55838539],\n",
       "       [5.25194358],\n",
       "       [4.9270096 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "            covars_weight=1, init_params='cm', means_prior=0, means_weight=0,\n",
       "            min_covar=0.001, n_components=4, n_iter=10, params='mtc',\n",
       "            random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "            transmat_prior=1.0, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\",init_params=\"cm\", params=\"mtc\")\n",
    "lr.startprob_ = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "lr.transmat_ = np.array([[0.5, 0.5, 0.0, 0.0],[0.0, 0.5, 0.5, 0.0],[0.0, 0.0, 0.5, 0.5],[0.0,0.0,0.0,1.0]])\n",
    "lr.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99883647, 0.00116353, 0.        , 0.        ],\n",
       "       [0.        , 0.98876026, 0.01123974, 0.        ],\n",
       "       [0.        , 0.        , 0.02136599, 0.97863401],\n",
       "       [0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.998836</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988760</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021366</td>\n",
       "      <td>0.978634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.998836  0.001164  0.000000  0.000000\n",
       "1  0.000000  0.988760  0.011240  0.000000\n",
       "2  0.000000  0.000000  0.021366  0.978634\n",
       "3  0.000000  0.000000  0.000000  1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lr.transmat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.97326008],\n",
       "        [5.98102124],\n",
       "        [5.31495996],\n",
       "        [5.883032  ]]), array([[[0.57548234]],\n",
       " \n",
       "        [[0.42177685]],\n",
       " \n",
       "        [[0.44305205]],\n",
       " \n",
       "        [[0.40793326]]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.means_, lr.covars_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = .5 * np.tile(np.identity(1), (4, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5]],\n",
       "\n",
       "       [[0.5]],\n",
       "\n",
       "       [[0.5]],\n",
       "\n",
       "       [[0.5]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
